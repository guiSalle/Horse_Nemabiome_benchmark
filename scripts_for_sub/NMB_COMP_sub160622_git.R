library("knitr")
library("BiocStyle")
require('ggplot2')
require('gridExtra')
require('dada2')
require('phyloseq')
require(dplyr)
library(data.table)
library(scales)
library(ggridges)
require(stringi)
require(stringr)
library(readr)
library(DECIPHER)
library(ShortRead)
library(Biostrings)
library(Hmisc)
require(car)

theme_set(theme_bw())

source('~/Documents/Scripts/multiplot.R')

###### Compare MOCKS

###### Compare files generated by NMB_XP_MOCK.R and NMB_XP_MOCK_Trimend.R

path <- "/MOCK_paper/"
setwd(path)

##### Update db for cox-1 // done November 12th 2021
#batch_download("./strongylidae99_mt.csv", "config99_mt.txt")
# Downloaded 89 sequences for Strongylinae in 1.4 secs from BOLD.
# Downloaded 641 sequences for Cyathostominae in 1.3 secs from BOLD.
# 48 seqences detected for Strongylinae
# Not using subsetting! (set GB_subset=2000 if downloading takes too long or crashes)
# Downloaded 48 sequences for Strongylinae in 4.7 secs from NCBI.
# 612 seqences detected for Cyathostominae
# Not using subsetting! (set GB_subset=2000 if downloading takes too long or crashes)
# Downloaded 612 sequences for Cyathostominae in 9.5 secs from NCBI.
# 11 Mitogenomes detected for Strongylinae
# 1
# 2
# 3
# 4
# 5
# 6
# 7
# 8
# 9
# 10
# 11
# Downloaded 11 mitogenomes for Strongylinae in 17 secs.
# 27 Mitogenomes detected for Cyathostominae
# 1
# 2
# 3
# 4
# 5
# 6
# 7
# 8
# 9
# 10
# 11
# 12
# 13
# 14
# 15
# 16
# 17
# 18
# 19
# 20
# 21
# 22
# 23
# 24
# 25
# 26
# 27
# Downloaded 27 mitogenomes for Cyathostominae in 40 secs.
# 
# Converted 27 mitogenomes of Strongylidae99_mt/Strongylidae99_mt/Cyathostominae_mito.gb to 17 unique COi sequences.
# Converted 11 mitogenomes of Strongylidae99_mt/Strongylidae99_mt/Strongylinae_mito.gb to 6 unique COi sequences.
# 
# Mitogenomes in which no marker sequences were detected: MN792800
# 
# Clipping: Left 0 bp, Right 0 bp
# Files writen in fasta
# Strongylidae99_mt/Strongylidae99_mt/Cyathostominae_BOLD.fasta Strongylidae99_mt/Strongylidae99_mt/Strongylinae_BOLD.fasta
# 
# Clipping: Left 0 bp, Right 0 bp
# Files writen in fasta
# Strongylidae99_mt/Strongylidae99_mt/Cyathostominae_GB.fasta Strongylidae99_mt/Strongylidae99_mt/Strongylinae_GB.fasta
# 
# Clipping: Left 0 bp, Right 0 bp
# Files writen in fasta
# Strongylidae99_mt/Strongylidae99_mt/Cyathostominae_mito.fasta Strongylidae99_mt/Strongylidae99_mt/Strongylinae_mito.fasta
# 
# Clipping: Left 0 bp, Right 0 bp
# Files writen in fasta
# Strongylidae99_mt/Strongylidae99_mt_Bold.fasta Strongylidae99_mt/Strongylidae99_mt_GB.fasta Strongylidae99_mt/Strongylidae99_mt_mito.fasta
# 
# 
# Rading Strongylidae99_mt_all.fasta
# 1413 imput sequences -> 894 dereplicated sequences
# Clusters:  289

###----====== 
set.seed(100) # Initialize random number generator for reproducibility


######----------------------------------------------------------
##### ITS-2 dada2 BS optim - IDTAXA - Workentine, Poissant 2021
######----------------------------------------------------------

bc = 'ITS'

### Training set - once and for all
taxmeth = 'idtaxa'
train <- readDNAStringSet("~/db/idtaxa_03022022.fasta") 
tax <- read_tsv("~/db/idtaxa_03022022.tax") 

trainingSet <- LearnTaxa(train, names(train), tax)

for(mxee in c(11,25)){
  for(truncL in c(200, 217)){
    for(BS in c(-1,16,32)){
      print(c(bc,mxee,truncL,BS))
      
      ### Read in seqtab
      seqtab_nochim = read.table(file = paste0('./mock_DADA2/mock_dada2_R_',bc,'_mxee',mxee,'_trunc',truncL,'_BS',BS,'/output.tsv'),
                                 header=T)
      
      dim(seqtab_nochim)
      #[1] 189 105
      
      dna <- DNAStringSet(getSequences(seqtab_nochim$OTUID))
      seqtab_nochim$OTUID = paste0('ASV_',1:nrow(seqtab_nochim))
      rownames(seqtab_nochim) = seqtab_nochim$OTUID
      names(dna) = seqtab_nochim$OTUID
      seqtab_nochim$OTUID = NULL
      
      colnames(seqtab_nochim) = sapply(stringr::str_split(colnames(seqtab_nochim),'_'),
                                       function(x) x[1])
      
      colnames(seqtab_nochim) = paste0('mxee',mxee,'_trunc',truncL,'_BS',BS,'_',
                                       gsub('[.]','',colnames(seqtab_nochim)))
      
      
      metadata = data.frame(sample.id = colnames(seqtab_nochim))
      rownames(metadata) = metadata$sample.id
      metadata$bank = gsub(paste0('mxee',mxee,'_trunc',truncL,'_BS',BS,'_'),'',metadata$sample.id)
      metadata$method = paste0('mxee',mxee,'_trunc',truncL,'_BS',BS)
      
       
      ids <- IdTaxa(dna,
                    trainingSet,
                    strand = "both",
                    threshold = 50,
                    bootstraps = 100,
                    processors = NULL,
                    verbose = TRUE,
                    type = "extended")
      
      ranks <- c("kingdom","phylum", "class", "order", "family", "genus", "species") # ranks of interest
      # Convert the output object of class "Taxa" to a matrix analogous to the output from assignTaxonomy
      taxidITS <- t(sapply(ids, function(x) {
        m <- match(ranks, x$rank)
        taxa <- x$taxon[m]
        taxa[startsWith(taxa, "unclassified_")] <- NA
        taxa
      }))
      colnames(taxidITS) <- ranks; rownames(taxidITS) <- names(dna) #getSequences(seqtab_nochim)
      
      
      ps = phyloseq(
        otu_table(seqtab_nochim, taxa_are_rows = TRUE),
        tax_table(taxidITS),
        sample_data(metadata))
      
      # Phyloseq obj
      
      psITS = tax_glom(ps,taxrank='species',NArm=F)
      psITS
      psITS.t <- transform_sample_counts(psITS,
                                         function(OTU) OTU/sum(OTU))
      assign(paste0('ps_',bc,'_',taxmeth,'_mxee',mxee,'_BS',BS,'_Tl',truncL), psITS.t)
      
      nsp = length(unique(tax_table(psITS.t)[,7]))
      
      ITS_taxid.blast = plot_bar(psITS.t, x = 'bank', fill="species") +
        scale_fill_manual(values = viridis_pal(option='A')(nsp))+
        facet_wrap(~ method) + 
        theme(legend.position = 'bottom',text = element_text(size = 16),
              axis.text.x = element_text(size = 6),
              legend.title = element_blank())+ coord_flip() +
        guides(fill = guide_legend(nrow = 6))
      
      pdf(file = paste0('./mock_',paste0('ps_',bc,'_',taxmeth,'_mxee',mxee,'_BS',BS,'_Tl',truncL),'.pdf'))
      print(ITS_taxid.blast)
      dev.off()
      
    }
  }
}

######---------------------------------------------------------------
##### mock_MINIMAPm - mapping against clustered COI db at 97% or 99%
######---------------------------------------------------------------
### regex in R: (1) dot usually means "match any character"
#(2) * means The preceding item will be matched zero or more times.
#.* is the same as * in linux
### https://github.com/lh3/minimap2/issues/521

#### Step1: refine the set of parameters to be considered further
mock.sp = c('Cylicocyclus_nassatus','Coronocyclus_labratus',
            'Cylicocyclus_ashworthi','Cylicostephanus_calicatus',
            'Cyathostomum_catinatum','Cylicostephanus_goldi',
            'Cyathostomum_pateratum','Coronocyclus_labiatus',
            'Cylicostephanus_longibursatus','Cylicocyclus_insigne','Cylicocyclus_leptostomus')
evalmini = NULL
for( id in c(97, 99)){
  for( B in c(1:4)){
    for(k in c(10, 13, 15)){
      for(w in c(8, 9, 10)){                                                                                                                                    

        print(c(id,B,k,w))
        
        miniNofilt <- sort(list.files(paste0('./mock_MINIMAP/mock_MINIMAPm_clus',id,'_B',B,'_k',k,'_w',w ), 
                                      pattern = "^COI.*L001_nofilt_genomecov_d.txt.gz", full.names = TRUE))
        miniFilt <- sort(list.files(paste0('./mock_MINIMAP/mock_MINIMAPm_clus',id,'_B',B,'_k',k,'_w',w), 
                                    pattern = "^COI.*L001_genomecov_d.txt.gz", full.names = TRUE))
        
        otumini = NULL
        
        for(f in miniNofilt){
          samp = str_extract(basename(f), "^[^_]+")
          if(file.size(f) == 20){
            print(c(f,'empty'))
          }else{
            mn = read.table(file = f)
            
            mn = mn[mn$V3!=0,]
            
            if(sum(mn$V3)>0){
              mn$V1 = sapply(stringr::str_split(mn$V1,"_"),function(x) paste(x[1],x[2],x[3],sep="_"))
              mn$V1 = sapply(stringr::str_split(mn$V1,"_"),function(x) paste(x[2],x[3],sep="_"))
              
              a = aggregate(V3 ~ V1, FUN=sum, data = mn)
              a = data.frame(a)
              a$samp = samp
              a$Filt = 'NoFilt'
              otumini = rbind(otumini,a)
            }
          }
        }
        
        for(f in miniFilt){
          samp = str_extract(basename(f), "^[^_]+")
          if(file.size(f) == 20){
            print(c(f,'empty'))
          }else{
            mn = read.table(file = f)
            
            mn = mn[mn$V3!=0,]
            
            if(sum(mn$V3)>0){
              mn$V1 = sapply(stringr::str_split(mn$V1,"_"),function(x) paste(x[1],x[2],x[3],sep="_"))
              mn$V1 = sapply(stringr::str_split(mn$V1,"_"),function(x) paste(x[2],x[3],sep="_"))
              
              a = aggregate(V3 ~ V1, FUN=sum, data = mn)
              a = data.frame(a)
              a$samp = samp
              a$Filt = 'Filt'
              otumini = rbind(otumini,a)
            }
          }
        }
        
        ###------ Need to correct wrong species names for COI
        unique(otumini$V1)
        # [1] "Cylicocyclus_nassatus"     "Coronocyclus_labiatus"     "Cylicostephanus_minutus"  
        # [4] "Cyathostomum_catinatum"    "ashworthi_Cylicocyclus"    "Cyathostomum_pateratum"   
        # [7] "Cylicocyclus_ashworthi"    "Cylicostephanus_calicatus"
        
        unique(otumini$V1)
        
        otumini$V1[otumini$V1=="catinatum_Cyathostomum"]='Cyathostomum_catinatum'
        otumini$V1[otumini$V1=="nassatus_Cylicocyclus"]='Cylicocyclus_nassatus'
        otumini$V1[otumini$V1=="goldi_Cylicostephanus"]='Cylicostephanus_goldi'
        
        otumini$V1[otumini$V1=="insigne_Cylicocyclus"]='Cylicocyclus_insigne'
        otumini$V1[otumini$V1=="auriculatus_Cylicocyclus"]='Cylicocyclus_auriculatus'
        otumini$V1[otumini$V1=="radiatus_Cylicocyclus"]='Cylicocyclus_radiatus'
        otumini$V1[otumini$V1=="minutus_Cylicostephanus"]='Cylicostephanus_minutus'
        otumini$V1[otumini$V1=="bicoronatus_Cylicodontophorus"]='Cylicodontophorus_bicoronatus'
        otumini$V1[otumini$V1=='nipponicus_Triodontophorus']='Triodontophorus_nipponicus'
        otumini$V1[otumini$V1=='vulgaris_Strongylus']='Strongylus_vulgaris'
        
        otumini$V1[grep('vulgaris_NA',otumini$V1)]='Strongylus_vulgaris'
        otumini$V1[grep('goldi_NA',otumini$V1)]='Cylicostephanus_goldi'
        otumini$V1[grep('minutus_NA',otumini$V1)]='Cylicostephanus_minutus'
        otumini$V1[grep('brevicauda_NA',otumini$V1)]='Triodontophorus_brevicauda'
        otumini$V1[grep('insigne_NA',otumini$V1)]='Cylicocyclus_insigne'
        otumini$V1[grep('auriculatus_NA',otumini$V1)]='Cylicocyclus_auriculatus'
        otumini$V1[grep('catinatum_NA',otumini$V1)]='Cyathostomum_catinatum'
        otumini$V1[grep('nassatus_NA',otumini$V1)]='Cylicocyclus_nassatus'
        otumini$V1[grep('ashworthi_NA',otumini$V1)]='Cylicocyclus_ashworthi'
        otumini$V1[grep('pateratum_NA',otumini$V1)]='Cyathostomum_pateratum'
        otumini$V1[grep('labiatus_NA',otumini$V1)]='Coronocyclus_labiatus'
        otumini$V1[grep('radiatus_NA',otumini$V1)]='Cylicocyclus_radiatus'
        otumini$V1[grep('nipponicus_NA',otumini$V1)]='Triodontophorus_nipponicus'
        
        otumini$V1[grep('C.nassatus_5.8S',otumini$V1)]='Cylicocyclus_nassatus'
        otumini$V1[grep('C.ashworthi_5.8S',otumini$V1)]='Cylicocyclus_ashworthi'
        
        otumini$V1[grep('C.catinatum_ribosomal',otumini$V1)]='Cyathostomum_catinatum'
        otumini$V1[grep('pateratum',otumini$V1)]='Cyathostomum_pateratum'
        otumini$V1[grep('insignis',otumini$V1)]='Cylicocyclus_insigne'
        otumini$V1[grep('labratum',otumini$V1)]='Coronocyclus_labratus'
        otumini$V1[grep('ashworthi',otumini$V1)]='Cylicocyclus_ashworthi'
        otumini$V1[grep('Cyathostomum_coronatum',otumini$V1)]='Coronocyclus_coronatus'
        otumini$V1[grep('Cyathostominae_sp.',otumini$V1)]='NA_NA'
        otumini$V1[grep('Cyathostominae',otumini$V1)]='NA_NA'
        unique(otumini$V1)
        # [1] "Cylicocyclus_nassatus"     "Coronocyclus_labiatus"     "Cylicostephanus_minutus"  
        # [4] "Cyathostomum_catinatum"    "Cylicocyclus_ashworthi"    "Cyathostomum_pateratum"   
        # [7] "Cylicostephanus_calicatus"
        
        ###-------- Convert minimap output to phyloseq object
        
        dt = otumini %>% reshape2::acast(samp + Filt ~ V1, value.var = 'V3',fun.aggregate = sum)
        dt = data.frame(dt)
        
        ranks <- c("kingdom","phylum", "class", "order", "family", "genus", "species") # ranks of interest
        tax.out <- matrix(NA_character_, nrow = ncol(dt), ncol = length(ranks))
        rownames(tax.out) = colnames(dt)
        
        filltax = c('Animalia','Nematoda','Chromadorea','Rhabditida','Strongylidae')
        for(i in seq(ncol(tax.out))){
          tax.out[,i] = filltax[i]
        }
        
        tax.out[,6] = sapply(stringr::str_split(colnames(dt),"_"),
                             function(x) x[1])
        tax.out[,7] = rownames(tax.out)
        tax.out[tax.out[,7]=='NA_NA',7] = NA
        unique(tax.out[,7])
        # [1] "Coronocyclus_labiatus"     "Cyathostomum_catinatum"    "Cyathostomum_pateratum"   
        # [4] "Cylicocyclus_ashworthi"    "Cylicocyclus_nassatus"     "Cylicostephanus_calicatus"
        # [7] "Cylicostephanus_minutus"
        
        colnames(tax.out) = ranks
        
        rownames(dt) = gsub('-','',rownames(dt))
        samples = rownames(dt)

        ### Keep track of taxa number and FP
        tmp = data.frame(meth = paste0('clus',id,'_B',B,'_k',k,'_w',w),
                           ntax = ncol(dt),
                         ntp = length(which(colnames(dt) %in% mock.sp)),
                         nfp = length(which(!(colnames(dt) %in% mock.sp))))
        evalmini = rbind(evalmini,tmp)
        rm(otumini,tmp)
      }
    }
  }
}

### First evaluation to keep the most different comparisons
evalmini$meth = gsub('./mock_MINIMAPm_','',evalmini$meth)

evalmini_exp = evalmini
evalmini_exp$B = sapply(stringr::str_split(evalmini_exp$meth,'_'),function(x) x[2])
evalmini_exp$k = sapply(stringr::str_split(evalmini_exp$meth,'_'),function(x) x[3])
evalmini_exp$w = sapply(stringr::str_split(evalmini_exp$meth,'_'),function(x) x[4])

head(evalmini_exp)

write.csv(evalmini_exp,file = './supplementary_Table1.csv',quote = F,row.names=F)
# meth ntax ntp nfp  B   k   w
# 1  clus97_B1_k10_w8   15   9   6 B1 k10  w8
# 2  clus97_B1_k10_w9   14   9   5 B1 k10  w9
# 3 clus97_B1_k10_w10   13   9   4 B1 k10 w10
# 4  clus97_B1_k13_w8   14   9   5 B1 k13  w8
# 5  clus97_B1_k13_w9   14   9   5 B1 k13  w9
# 6 clus97_B1_k13_w10   13   9   4 B1 k13 w10

## Reshape for plot
evalmini = reshape2::melt(evalmini,1)
evalmini$clus = substr(evalmini$meth,1,6)
evalmini$B = sapply(stringr::str_split(evalmini$meth,'_'),function(x) x[2])
evalmini$k = sapply(stringr::str_split(evalmini$meth,'_'),function(x) x[3])
evalmini$w = sapply(stringr::str_split(evalmini$meth,'_'),function(x) x[4])

## Clustering of the initial db affects # of FP ; we skip 97% clustering as it does not improve # of TPs, & has higher FP rate.
ggplot(evalmini,aes(x = clus, y = value)) +
  geom_point() + facet_wrap(~ variable) + 
  scale_y_continuous(limits = c(0,14),breaks = c(0:16))

## B=3 or B=4 are similar; keep 4 (default value in minimap)
ggplot(evalmini,aes(x = B, y = value)) +
  geom_point() + facet_wrap(~ variable)+ 
  scale_y_continuous(limits = c(0,14),breaks = c(0:16))

## k13 is intermediate between k=10 and k=15; keep all 3
ggplot(evalmini,aes(x = k, y = value)) +
  geom_point() + facet_wrap(~ variable)+ 
  scale_y_continuous(limits = c(0,14),breaks = c(0:16))

## w = 9 is not different from w=10; skip this value
ggplot(evalmini,aes(x = w, y = value)) +
  geom_point() + facet_wrap(~ variable)+ 
  scale_y_continuous(limits = c(0,14),breaks = c(0:16))


#### Step2: Retain the combinations of interest for full range of evaluation (18 sets)
id = 99
for(B in c(1,2,4)){
  for(k in c(10, 13, 15)){
    for(w in c(8, 10)){                                                                                                                                    
      
      #print(c(id,B,k,w))
      
      miniNofilt <- sort(list.files(paste0('./mock_MINIMAP/mock_MINIMAPm_clus',id,'_B',B,'_k',k,'_w',w ), 
                                    pattern = "^COI.*L001_nofilt_genomecov_d.txt.gz", full.names = TRUE))
      miniFilt <- sort(list.files(paste0('./mock_MINIMAP/mock_MINIMAPm_clus',id,'_B',B,'_k',k,'_w',w), 
                                  pattern = "^COI.*L001_genomecov_d.txt.gz", full.names = TRUE))
      
      otumini = NULL
      
      for(f in miniNofilt){
        samp = str_extract(basename(f), "^[^_]+")
        if(file.size(f) == 20){
          print(c(f,'empty'))
        }else{
          ## Read in genome cov stats
          mn = read.table(file = f)
          
          ## Extract seq length (nb of occurrences in the file)
          seqlen = data.frame(table(mn$V1))
          colnames(seqlen)[1]='V1'
          colnames(seqlen)[2]='Seqlen'
          
          ## Get rid of sequence positions with no read mapped
          mn = mn[mn$V3!=0,]
          
          if(sum(mn$V3)>0){
            mn$V1 = sapply(stringr::str_split(mn$V1,"_"),function(x) paste(x[1],x[2],x[3],sep="_"))
            mn$V1 = sapply(stringr::str_split(mn$V1,"_"),function(x) paste(x[2],x[3],sep="_"))
            seqlen$V1 = sapply(stringr::str_split(seqlen$V1,"_"),function(x) paste(x[1],x[2],x[3],sep="_"))
            seqlen$V1 = sapply(stringr::str_split(seqlen$V1,"_"),function(x) paste(x[2],x[3],sep="_"))
            
            ## Compute total coverage corrected by seq length (percentage coverage)
            a = aggregate(V3 ~ V1, FUN = sum, data = mn)
            a = data.frame(a)
            a$samp = samp
            a$Filt = 'NoFilt'
            a = merge(a,seqlen,by = 'V1')
            a$FracCov = a$V3/a$Seqlen
            otumini = rbind(otumini,a)
          }
        }
      }
      
      for(f in miniFilt){
        samp = str_extract(basename(f), "^[^_]+")
        if(file.size(f) == 20){
          print(c(f,'empty'))
        }else{
          ## Read in genome cov stats
          mn = read.table(file = f)
          
          ## Extract seq length (nb of occurrences in the file)
          seqlen = data.frame(table(mn$V1))
          colnames(seqlen)[1]='V1'
          colnames(seqlen)[2]='Seqlen'
          
          ## Get rid of sequence positions with no read mapped
          mn = mn[mn$V3!=0,]
          
          if(sum(mn$V3)>0){
            mn$V1 = sapply(stringr::str_split(mn$V1,"_"),function(x) paste(x[1],x[2],x[3],sep="_"))
            mn$V1 = sapply(stringr::str_split(mn$V1,"_"),function(x) paste(x[2],x[3],sep="_"))
            seqlen$V1 = sapply(stringr::str_split(seqlen$V1,"_"),function(x) paste(x[1],x[2],x[3],sep="_"))
            seqlen$V1 = sapply(stringr::str_split(seqlen$V1,"_"),function(x) paste(x[2],x[3],sep="_"))
            
            ## Compute total coverage corrected by seq length (percentage coverage)
            a = aggregate(V3 ~ V1, FUN = sum, data = mn)
            a = data.frame(a)
            a$samp = samp
            a$Filt = 'Filt'
            a = merge(a,seqlen,by = 'V1')
            a$FracCov = a$V3/a$Seqlen
            otumini = rbind(otumini,a)
          }
        }
      }
      
      ###------ Need to correct wrong species names for COI
      unique(otumini$V1)
      # [1] "Cylicocyclus_nassatus"     "Coronocyclus_labiatus"     "Cylicostephanus_minutus"  
      # [4] "Cyathostomum_catinatum"    "ashworthi_Cylicocyclus"    "Cyathostomum_pateratum"   
      # [7] "Cylicocyclus_ashworthi"    "Cylicostephanus_calicatus"
      
      unique(otumini$V1)
      
      otumini$V1[otumini$V1=="catinatum_Cyathostomum"]='Cyathostomum_catinatum'
      otumini$V1[otumini$V1=="nassatus_Cylicocyclus"]='Cylicocyclus_nassatus'
      otumini$V1[otumini$V1=="goldi_Cylicostephanus"]='Cylicostephanus_goldi'
      
      otumini$V1[otumini$V1=="insigne_Cylicocyclus"]='Cylicocyclus_insigne'
      otumini$V1[otumini$V1=="auriculatus_Cylicocyclus"]='Cylicocyclus_auriculatus'
      otumini$V1[otumini$V1=="radiatus_Cylicocyclus"]='Cylicocyclus_radiatus'
      otumini$V1[otumini$V1=="minutus_Cylicostephanus"]='Cylicostephanus_minutus'
      otumini$V1[otumini$V1=="bicoronatus_Cylicodontophorus"]='Cylicodontophorus_bicoronatus'
      otumini$V1[otumini$V1=='nipponicus_Triodontophorus']='Triodontophorus_nipponicus'
      otumini$V1[otumini$V1=='vulgaris_Strongylus']='Strongylus_vulgaris'
      
      otumini$V1[grep('vulgaris_NA',otumini$V1)]='Strongylus_vulgaris'
      otumini$V1[grep('goldi_NA',otumini$V1)]='Cylicostephanus_goldi'
      otumini$V1[grep('minutus_NA',otumini$V1)]='Cylicostephanus_minutus'
      otumini$V1[grep('brevicauda_NA',otumini$V1)]='Triodontophorus_brevicauda'
      otumini$V1[grep('insigne_NA',otumini$V1)]='Cylicocyclus_insigne'
      otumini$V1[grep('auriculatus_NA',otumini$V1)]='Cylicocyclus_auriculatus'
      otumini$V1[grep('catinatum_NA',otumini$V1)]='Cyathostomum_catinatum'
      otumini$V1[grep('nassatus_NA',otumini$V1)]='Cylicocyclus_nassatus'
      otumini$V1[grep('ashworthi_NA',otumini$V1)]='Cylicocyclus_ashworthi'
      otumini$V1[grep('pateratum_NA',otumini$V1)]='Cyathostomum_pateratum'
      otumini$V1[grep('labiatus_NA',otumini$V1)]='Coronocyclus_labiatus'
      otumini$V1[grep('radiatus_NA',otumini$V1)]='Cylicocyclus_radiatus'
      otumini$V1[grep('nipponicus_NA',otumini$V1)]='Triodontophorus_nipponicus'
      
      otumini$V1[grep('C.nassatus_5.8S',otumini$V1)]='Cylicocyclus_nassatus'
      otumini$V1[grep('C.ashworthi_5.8S',otumini$V1)]='Cylicocyclus_ashworthi'
      
      otumini$V1[grep('C.catinatum_ribosomal',otumini$V1)]='Cyathostomum_catinatum'
      otumini$V1[grep('pateratum',otumini$V1)]='Cyathostomum_pateratum'
      otumini$V1[grep('insignis',otumini$V1)]='Cylicocyclus_insigne'
      otumini$V1[grep('labratum',otumini$V1)]='Coronocyclus_labratus'
      otumini$V1[grep('ashworthi',otumini$V1)]='Cylicocyclus_ashworthi'
      otumini$V1[grep('Cyathostomum_coronatum',otumini$V1)]='Coronocyclus_coronatus'
      otumini$V1[grep('Cyathostominae_sp.',otumini$V1)]='NA_NA'
      otumini$V1[grep('Cyathostominae',otumini$V1)]='NA_NA'
      unique(otumini$V1)
      # [1] "Cylicocyclus_nassatus"     "Coronocyclus_labiatus"     "Cylicostephanus_minutus"  
      # [4] "Cyathostomum_catinatum"    "Cylicocyclus_ashworthi"    "Cyathostomum_pateratum"   
      # [7] "Cylicostephanus_calicatus"
      
      ###-------- Convert minimap output to phyloseq object
      require(car)
      dt = otumini %>% reshape2::acast(samp + Filt ~ V1, value.var = 'V3',fun.aggregate = sum)
      dt = data.frame(dt)
      
      ranks <- c("kingdom","phylum", "class", "order", "family", "genus", "species") # ranks of interest
      tax.out <- matrix(NA_character_, nrow = ncol(dt), ncol = length(ranks))
      rownames(tax.out) = colnames(dt)
      
      filltax = c('Animalia','Nematoda','Chromadorea','Rhabditida','Strongylidae')
      for(i in seq(ncol(tax.out))){
        tax.out[,i] = filltax[i]
      }
      
      tax.out[,6] = sapply(stringr::str_split(colnames(dt),"_"),
                           function(x) x[1])
      tax.out[,7] = rownames(tax.out)
      tax.out[tax.out[,7]=='NA_NA',7] = NA
      unique(tax.out[,7])
      # [1] "Coronocyclus_labiatus"     "Cyathostomum_catinatum"    "Cyathostomum_pateratum"   
      # [4] "Cylicocyclus_ashworthi"    "Cylicocyclus_nassatus"     "Cylicostephanus_calicatus"
      # [7] "Cylicostephanus_minutus"
      
      colnames(tax.out) = ranks
      
      rownames(dt) = gsub('-','',rownames(dt))
      samples = paste0('clus',id,'_B',B,'_k',k,'_w',w,'_',rownames(dt))
      rownames(dt) = samples
      
      samp_data <-  data.frame(
        row.names = samples,
        sample.id = samples,
        bank = sapply(stringr::str_split(samples,"_"), function(x) x[5]),
        method = paste0('clus',id,'_B',B,'_k',k,'_w',w,'_',sapply(stringr::str_split(samples,"_"), function(x) x[6]))
      )
      psCOI.blast = phyloseq(
        otu_table(dt, taxa_are_rows = FALSE),
        tax_table(tax.out),
        sample_data(samp_data)
      )
      
      psCOI = tax_glom(psCOI.blast,taxrank='species',NArm=F)
      psCOI.t <- transform_sample_counts(psCOI,
                                         function(OTU) OTU/sum(OTU))
      
      assign(paste0('minimap_clus',id,'_B',B,'_k',k,'_w',w),
             psCOI.t)
      print(paste0('minimap_clus',id,'_B',B,'_k',k,'_w',w))
      
      COI_taxid.blast = plot_bar(psCOI.t, x = 'sample.id', fill="species") +
        scale_fill_manual(values = viridis_pal(option='A')(nrow(tax_table(psCOI.t))))+
        #facet_wrap(~ method) +
        theme(legend.position = 'bottom',text = element_text(size = 16),
              axis.text.x = element_text(size = 6),
              legend.title = element_blank())+ coord_flip() +
        guides(fill = guide_legend(nrow = 6))
      
      pdf(file = paste0('./mock_MINIMAPm_clus',id,'_B',B,'_k',k,'_w',w ,'.pdf'),width=14,height=8)
      print(COI_taxid.blast)
      dev.off()
      
      rm(psCOI.t,psCOI,otumini)
    }
  }
}


######-----------------------------------------------------
##### mock_community
######-----------------------------------------------------

#### Set up the otu_table for expected communities

### TAX
ranks <- c("kingdom","phylum", "class", "order", "family", "genus", "species") # ranks of interest
tax.mock <- matrix(NA_character_, nrow = 11, ncol = length(ranks))
mock.sp = c('Cylicocyclus_nassatus','Coronocyclus_labratus',
            'Cylicocyclus_ashworthi','Cylicostephanus_calicatus',
            'Cyathostomum_catinatum','Cylicostephanus_goldi',
            'Cyathostomum_pateratum','Coronocyclus_labiatus',
            'Cylicostephanus_longibursatus','Cylicocyclus_insigne','Cylicocyclus_leptostomus')
filltax = c('Eukaryota','Metazoa',"Chromadorea","Strongylida",
            "Strongylidae")

for(i in seq(ncol(tax.mock))){
  tax.mock[,i]=filltax[i]
}
tax.mock[,6] = sapply(stringr::str_split(mock.sp,"_"),
                     function(x) x[1])
tax.mock[,7] = mock.sp

colnames(tax.mock) = ranks
rownames(tax.mock) = mock.sp

#### METADATA
samp = str_extract(basename(miniNofilt), "^[^_]+") #substr(,4,nchar(str_extract(basename(miniNofilt), "^[^_]+")))

unique(samp)
#[1] "CP-12"    "M1"       "M1-1"     "M2"       "M2-1"     "M3"       "M4"       "M5"       "Meq"      "Meq-C12"  "MS10"     "MS10-C12"
#[13] "CP-ITS"   "M3-1"     "M4-1"     "M5-1"     "Meq-ITS"  "MS10-ITS"

meta.mock = data.frame(bc = substr(samp,1,3), 
                       sample.id = str_extract(basename(substr(samp,4,nchar(samp))), "^[^-]+"),
                       rep = sapply(stringr::str_split(substr(samp,4,nchar(samp)),"-"),function(x) x[2]))
meta.mock$rep[is.na(meta.mock$rep)] = 0

#### EXPECTED OTU TABLE
unique(meta.mock$sample.id)
#[1] "CP"   "M1"   "M2"   "M3"   "M4"   "M5"   "Meq"  "MS10"

mms = c(unique(meta.mock$sample.id),'M11','M21','MeqC12','MS10C12','CP12','M31','M41','M51')

otu.mock = matrix(0,nrow = length(mock.sp),
                  ncol = length(mms))
colnames(otu.mock) = mms
rownames(otu.mock) = mock.sp

otu.mock[c(grep("pateratum" , rownames(otu.mock)), grep("catinatum" ,rownames(otu.mock))),1] = 1 ## CP

otu.mock[c(grep("catinatum",rownames(otu.mock)), 
           grep("labiatus", rownames(otu.mock)), grep("nassatus",rownames(otu.mock)),
           grep("insigne", rownames(otu.mock))),3] = 1 ## M2
otu.mock[c(grep("pateratum",rownames(otu.mock))),3] = 2 ## M2

otu.mock[c(grep("pateratum", rownames(otu.mock))),4] = 3 ## M3
otu.mock[c(grep("catinatum", rownames(otu.mock))),4] = 1 ## M3

otu.mock[c(grep("pateratum", rownames(otu.mock)) , grep("catinatum",rownames(otu.mock))),5] = 1 ## M4
otu.mock[c(grep("pateratum", rownames(otu.mock))),6] = 1 ## M5
otu.mock[c(grep("catinatum", rownames(otu.mock))),6] = 3 ## M5

otu.mock[,7] = rep(0.135,nrow(otu.mock))*1/12 ## Meq
otu.mock[c(grep("pateratum", rownames(otu.mock))),7] = 2*0.135/12 ## Meq

otu.mock[,8] = c(1.28,0.251,0.549,0.553,0.126,1.08,0.135,2.45+2.69,0.498,1.34,1.06)*2/24/10 ## MS10
otu.mock[c(grep("catinatum",rownames(otu.mock)), 
           grep("labiatus", rownames(otu.mock)), grep("nassatus",rownames(otu.mock)),
           grep("insigne", rownames(otu.mock))),2] = c(3.84,9.12,6.44,2.24)*3/18  ## M2
otu.mock[c(grep("pateratum", rownames(otu.mock))),2] = 33.64*3/18 ## M2

otu.mock[,9] = otu.mock[,2]
otu.mock[,10] = otu.mock[,3]
otu.mock[,11] = otu.mock[,7]
otu.mock[,12] = otu.mock[,8]
otu.mock[,13] = otu.mock[,1]
otu.mock[,14] = otu.mock[,4]
otu.mock[,15] = otu.mock[,5]
otu.mock[,16] = otu.mock[,6]

### Replace C. radiatus with C. pateratum to correct for tube swapping

#otu.mock = t(t(otu.mock)/rowSums(t(otu.mock)))
otu.mock
#                               CP    M1 M2 M3 M4 M5    Meq    MS10   M11 M21 MeqC12 MS10C12 CP12 M31 M41 M51
# Cylicocyclus_nassatus          0 1.073  1  0  0  0 0.0113 0.01067 1.073   1 0.0113 0.01067    0   0   0   0
# Coronocyclus_labratus          0 0.000  0  0  0  0 0.0113 0.00209 0.000   0 0.0113 0.00209    0   0   0   0
# Cylicocyclus_ashworthi         0 0.000  0  0  0  0 0.0113 0.00458 0.000   0 0.0113 0.00458    0   0   0   0
# Cylicostephanus_calicatus      0 0.000  0  0  0  0 0.0113 0.00461 0.000   0 0.0113 0.00461    0   0   0   0
# Cyathostomum_catinatum         1 0.640  1  1  1  3 0.0113 0.00105 0.640   1 0.0113 0.00105    1   1   1   3
# Cylicostephanus_goldi          0 0.000  0  0  0  0 0.0113 0.00900 0.000   0 0.0113 0.00900    0   0   0   0
# Cyathostomum_pateratum         1 5.607  2  3  1  1 0.0225 0.00113 5.607   2 0.0225 0.00113    1   3   1   1
# Coronocyclus_labiatus          0 1.520  1  0  0  0 0.0113 0.04283 1.520   1 0.0113 0.04283    0   0   0   0
# Cylicostephanus_longibursatus  0 0.000  0  0  0  0 0.0113 0.00415 0.000   0 0.0113 0.00415    0   0   0   0
# Cylicocyclus_insigne           0 0.373  1  0  0  0 0.0113 0.01117 0.373   1 0.0113 0.01117    0   0   0   0
# Cylicocyclus_leptostomus       0 0.000  0  0  0  0 0.0113 0.00883 0.000   0 0.0113 0.00883    0   0   0   0

## Build phyloseq object to check we are OK
samples = mms
samp_data <-  data.frame(
  row.names = samples,
  sample.id = samples
)

ps.mock = phyloseq(
  otu_table(otu.mock, taxa_are_rows = TRUE),
  tax_table(tax.mock),
  sample_data(samp_data)
)

ps.mock.t = transform_sample_counts(ps.mock,function(x) x/sum(x))

ps.mock.sp = tax_glom(ps.mock.t,taxrank='species',NArm=F)
ps.mock.sp
# phyloseq-class experiment-level object
# otu_table()   OTU Table:         [ 11 taxa and 16 samples ]
# sample_data() Sample Data:       [ 16 samples by 1 sample variables ]
# tax_table()   Taxonomy Table:    [ 11 taxa by 7 taxonomic ranks ]

######--------------------------------------------------------------------
####--------- Compute divergence / richness / TP, FP / recall & precision
######--------------------------------------------------------------------

df.list = c(`ps_ITS_idtaxa_mxee11_BS-1_Tl200`,
            `ps_ITS_idtaxa_mxee11_BS-1_Tl217`,
            ps_ITS_idtaxa_mxee11_BS16_Tl200,
            ps_ITS_idtaxa_mxee11_BS16_Tl217,
            ps_ITS_idtaxa_mxee11_BS32_Tl200,
            ps_ITS_idtaxa_mxee11_BS32_Tl217,
            `ps_ITS_idtaxa_mxee25_BS-1_Tl200`,
            `ps_ITS_idtaxa_mxee25_BS-1_Tl217`,
            ps_ITS_idtaxa_mxee25_BS16_Tl200,
            ps_ITS_idtaxa_mxee25_BS16_Tl217,
            ps_ITS_idtaxa_mxee25_BS32_Tl200,
            ps_ITS_idtaxa_mxee25_BS32_Tl217,
            minimap_clus99_B1_k10_w8,
            minimap_clus99_B1_k10_w10,
            minimap_clus99_B1_k13_w8,
            minimap_clus99_B1_k13_w10,
            minimap_clus99_B1_k15_w8,
            minimap_clus99_B1_k15_w10,
            minimap_clus99_B2_k10_w8,
            minimap_clus99_B2_k10_w10,
            minimap_clus99_B2_k13_w8,
            minimap_clus99_B2_k13_w10,
            minimap_clus99_B2_k15_w8,
            minimap_clus99_B2_k15_w10,
            minimap_clus99_B4_k10_w8,
            minimap_clus99_B4_k10_w10,
            minimap_clus99_B4_k13_w8,
            minimap_clus99_B4_k13_w10,
            minimap_clus99_B4_k15_w8,
            minimap_clus99_B4_k15_w10)

### Prep phyloseq object
samples = mms
samp_data <-  data.frame(
  row.names = samples,
  sample.id = samples,
  bank = mms,
  method = rep('mockITSCOI',ncol(otu.mock))
)

ps.mock.d = phyloseq(
  otu_table(otu.mock, taxa_are_rows = TRUE),
  tax_table(tax.mock),
  sample_data(samp_data)
)
ps.mock.d.t = transform_sample_counts(ps.mock.d, function(OTU) OTU/sum(OTU))
rm(samp_data)

### Merge ALL data
gp = merge_phyloseq(`ps_ITS_idtaxa_mxee11_BS-1_Tl200`,
                    `ps_ITS_idtaxa_mxee11_BS-1_Tl217`,
                    ps_ITS_idtaxa_mxee11_BS16_Tl200,
                    ps_ITS_idtaxa_mxee11_BS16_Tl217,
                    ps_ITS_idtaxa_mxee11_BS32_Tl200,
                    ps_ITS_idtaxa_mxee11_BS32_Tl217,
                    `ps_ITS_idtaxa_mxee25_BS-1_Tl200`,
                    `ps_ITS_idtaxa_mxee25_BS-1_Tl217`,
                    ps_ITS_idtaxa_mxee25_BS16_Tl200,
                    ps_ITS_idtaxa_mxee25_BS16_Tl217,
                    ps_ITS_idtaxa_mxee25_BS32_Tl200,
                    ps_ITS_idtaxa_mxee25_BS32_Tl217,
                    minimap_clus99_B1_k10_w8,
                    minimap_clus99_B1_k10_w10,
                    minimap_clus99_B1_k13_w8,
                    minimap_clus99_B1_k13_w10,
                    minimap_clus99_B1_k15_w8,
                    minimap_clus99_B1_k15_w10,
                    minimap_clus99_B2_k10_w8,
                    minimap_clus99_B2_k10_w10,
                    minimap_clus99_B2_k13_w8,
                    minimap_clus99_B2_k13_w10,
                    minimap_clus99_B2_k15_w8,
                    minimap_clus99_B2_k15_w10,
                    minimap_clus99_B4_k10_w8,
                    minimap_clus99_B4_k10_w10,
                    minimap_clus99_B4_k13_w8,
                    minimap_clus99_B4_k13_w10,
                    minimap_clus99_B4_k15_w8,
                    minimap_clus99_B4_k15_w10,
                    ps.mock.d.t)

gp
# phyloseq-class experiment-level object
# otu_table()   OTU Table:         [ 72 taxa and 194 samples ]
# sample_data() Sample Data:       [ 194 samples by 3 sample variables ]
# tax_table()   Taxonomy Table:    [ 72 taxa by 7 taxonomic ranks ]

### Unify and correct taxonomy across datasets
taxcor = tax_table(gp)
filltax = c('Animalia','Nematoda','Chromadorea','Rhabditida','Strongylidae')
for(i in 1:5){
  taxcor[,i] = filltax[i]
}

sampcor = sample_data(gp)
sampcor$barcode = ''
sampcor$barcode[grep('COI',sampcor$sample.id)]='COI'
sampcor$barcode[grep('ITS',sampcor$sample.id)]='ITS'
sampcor$barcode[sampcor$method=='mockITSCOI'] = 'mock'
sampcor$bank[which(substr(sampcor$bank,1,3)=='ITS')] = substr(sampcor$bank[which(substr(sampcor$bank,1,3)=='ITS')],
                                                              4,nchar(sampcor$bank[which(substr(sampcor$bank,1,3)=='ITS')]))
sampcor$bank[which(substr(sampcor$bank,1,3)=='COI')] = substr(sampcor$bank[which(substr(sampcor$bank,1,3)=='COI')],
                                                              4,nchar(sampcor$bank[which(substr(sampcor$bank,1,3)=='COI')]))
gp = phyloseq(
              otu_table(gp),
              tax_table(taxcor),
              sample_data(sampcor))

gp = tax_glom(gp,taxrank='species',NArm=F)
gp
# phyloseq-class experiment-level object
# otu_table()   OTU Table:         [ 22 taxa and 194 samples ]
# sample_data() Sample Data:       [ 194 samples by 4 sample variables ]
# tax_table()   Taxonomy Table:    [ 22 taxa by 7 taxonomic ranks ]

# Generate color palette
pal = qualpalr::qualpal(n=nrow(tax_table(gp)), colorspace=list(h=c(0,360), s=c(0.3,1), l=c(0.2,0.8)))

p = plot_bar(gp, x = 'method', fill = "species") + 
  facet_wrap(~ bank) +
  scale_fill_manual(values = pal$hex) +
  theme(legend.position = 'bottom', text = element_text(size = 10),
        axis.text.y = element_text(size = 8),
        legend.title = element_blank())+ 
  coord_flip() +
  guides(fill = guide_legend(nrow = 8,override.aes = ))
#p$data$method = relevel(factor(p$data$method),ref = 'mockITSCOI')
#p

###---- Plot for COI
p2 = p
p2$data = p$data[c(grep('COI',p$data$barcode)),]

pdf(file='./Relabu_COI.pdf',width = 14,height = 8)
print(p2)
dev.off()

###---- Plot for ITS
p3 = p
p3$data = p$data[grep('ITS',p$data$barcode),]
pdf(file='./Relabu_ITS.pdf',width = 14,height = 8)
print(p3)
dev.off()

### Final update to sample_data
sampcor$method = gsub('_COI','',sampcor$method)
sampcor$method = gsub('_ITS','',sampcor$method)
sampcor$method = gsub('ITSCOI','',sampcor$method)

gp = phyloseq(
  otu_table(gp),
  tax_table(gp),
  sample_data(sampcor)
)
gp = tax_glom(gp,taxrank='species',NArm=F)
gp
# phyloseq-class experiment-level object
# otu_table()   OTU Table:         [ 22 taxa and 548 samples ]
# sample_data() Sample Data:       [ 548 samples by 4 sample variables ]
# tax_table()   Taxonomy Table:    [ 22 taxa by 7 taxonomic ranks ]

################
####-------- What species found or not found ?
################

# ## Meq and MS10 (12 species)
# meq.ps.12 = phyloseq(
#   otu_table(otu_table(gp)[,c(grep('Meq',colnames(otu_table(gp))),
#                              grep('MS',colnames(otu_table(gp))))]),
#   tax_table(gp),
#   sample_data(sampcor[c(grep('Meq',colnames(otu_table(gp))),
#                         grep('MS',colnames(otu_table(gp)))),])
# )
# meq.ps.12 = tax_glom(meq.ps.12,taxrank='species',NArm=F)
# 
# ## Get rid of rarest taxa
# meq.ps.12.fr = filter_taxa(meq.ps.12, function(x) sum(x) > .05, TRUE)
# 
# ## Set observation with rare detection rate to 0
# otu_table(meq.ps.12.fr)[otu_table(meq.ps.12.fr) < 5e-4] = 0
# 
# psbin <- transform_sample_counts(meq.ps.12.fr, function(x) ifelse(x > 0,1,0))
# o = order(otu_table(psbin)[,ncol(otu_table(psbin))],decreasing =T)
# 
# pdf(file = './SpeciesDetectionMatrixMeqMS.pdf',width = 14,height=8)
# print(pheatmap::pheatmap(otu_table(psbin)[o,],
#                          cluster_rows = F, cluster_cols = T,fontsize_col = 8,#cellheight = 14,
#                    color = viridis_pal(option='D')(2),
#                    legend_breaks = c(0,1),legend_labels = c('Absence','Presence'),
#                    labels_row = tax_table(psbin)[o,ncol(tax_table(psbin))],
#                    border_color = "grey60",gaps_row = 11))
# dev.off()
# 
# ## M1 and M2 (5 species)
# meq.ps.5 = phyloseq(
#   otu_table(otu_table(gp)[,c(grep('M1',colnames(otu_table(gp))),
#                              grep('M2',colnames(otu_table(gp))))]),
#   tax_table(taxcor),
#   sample_data(sampcor[c(grep('M1',colnames(otu_table(gp))),
#                         grep('M2',colnames(otu_table(gp)))),])
# )
# 
# meq.ps.5.fr = filter_taxa(meq.ps.5, function(x) sum(x) > .05, TRUE)
# otu_table(meq.ps.5.fr)[otu_table(meq.ps.5.fr) < 1e-5] = 0
# 
# psbin <- transform_sample_counts(meq.ps.5.fr, function(x) ifelse(x>0,1,0))
# o = order(otu_table(psbin)[,ncol(otu_table(psbin))],decreasing =T)
# 
# pdf(file = './SpeciesDetectionMatrixM1M2.pdf',width = 14,height=8)
# print(pheatmap::pheatmap(otu_table(psbin)[o,],
#                          cluster_rows = F, cluster_cols = T,fontsize_col = 8,#cellheight = 14,
#                          color = viridis_pal(option='D')(2),
#                          legend_breaks = c(0,1),legend_labels = c('Absence','Presence'),
#                          labels_row = tax_table(psbin)[o,ncol(tax_table(psbin))],
#                          border_color = "grey60",gaps_row = 5))
# dev.off()
# 
# ## M3:M5 (2 species)
# meq.ps.2 = phyloseq(
#   otu_table(otu_table(gp)[,c(grep('M3',colnames(otu_table(gp))),
#                              grep('M4',colnames(otu_table(gp))),
#                              grep('M5',colnames(otu_table(gp))),
#                              grep('CP',colnames(otu_table(gp))))]),
#   tax_table(taxcor),
#   sample_data(sampcor[c(grep('M3',colnames(otu_table(gp))),
#                         grep('M4',colnames(otu_table(gp))),
#                         grep('M5',colnames(otu_table(gp))),
#                         grep('CP',colnames(otu_table(gp)))),])
# )
# meq.ps.2 = tax_glom(meq.ps.2,taxrank = 'species',NArm = F)
# 
# psbin <- transform_sample_counts(meq.ps.2, function(x) ifelse(x>0,1,0))
# o = order(otu_table(psbin)[,ncol(otu_table(psbin))],decreasing =T)
# 
# pdf(file = './SpeciesDetectionMatrixM3M5.pdf',width = 14,height=8)
# print(pheatmap::pheatmap(otu_table(psbin)[o,],cluster_rows = F, cluster_cols = T,fontsize_col = 6,#cellheight = 14,
#                          color = viridis_pal(option='D')(2),
#                          legend_breaks = c(0,1),legend_labels = c('Absence','Presence'),
#                          labels_row = tax_table(psbin)[o,ncol(tax_table(psbin))],
#                          border_color = "grey60",gaps_row = 2))
# dev.off()
# 
# 
# add_comp = sample_data(gp)
# add_comp$complexity = 2
# add_comp$complexity[add_comp$bank %in% c("Meq","MS10","MeqC12","MS10C12","MeqITS","MS10ITS")] = 11
# add_comp$complexity[add_comp$bank %in% c("M1","M2","M11","M21")] = 5
# 
# mockCorfinal = phyloseq(
#   otu_table(gp),
#   tax_table(gp),
#   sample_data(add_comp)
# )
# 
# ################
# ####-------- Print heatmap pres/absence 
# ################
# for(cpx in c(2,5,11)){
#   ps = subset_samples(mockCorfinal,complexity == cpx & barcode %in% c('COI','mock'))
#   ps = filter_taxa(ps, function(x) sum(x) > 0, TRUE)
#   psbin <- transform_sample_counts(ps, function(x) ifelse(x>0,1,0))
#   
#   o = order(otu_table(psbin)[,ncol(otu_table(psbin))],decreasing =T)
#   
#   pdf(file = paste0('./SpDetectMatrix_COI_',cpx,'.pdf'),width = 14, height = 9)
#   print(pheatmap::pheatmap(otu_table(psbin)[o,],cluster_rows = F, cluster_cols = T,fontsize_col = 8,
#                            color = viridis_pal(option='D')(2),
#                            legend_breaks = c(0,1),legend_labels = c('Absence','Presence'),
#                            labels_row = tax_table(psbin)[o,ncol(tax_table(psbin))],
#                            border_color = "grey60", gaps_row = cpx))
#   dev.off()
# }
# for(cpx in c(2,5,11)){
#   ps = subset_samples(mockCorfinal,complexity == cpx & barcode %in% c('ITS','mock'))
#   ps = filter_taxa(ps, function(x) sum(x) > 0, TRUE)
#   psbin <- transform_sample_counts(ps, function(x) ifelse(x>0,1,0))
#   o = order(otu_table(psbin)[,ncol(otu_table(psbin))],decreasing =T)
#   
#   pdf(file = paste0('./SpDetectMatrix_ITS_',cpx,'.pdf'),width = 14, height = 9)
#   print(pheatmap::pheatmap(otu_table(psbin)[o,],cluster_rows = F, cluster_cols = T,fontsize_col = 8,
#                            color = viridis_pal(option='D')(2),
#                            legend_breaks = c(0,1),legend_labels = c('Absence','Presence'),
#                            labels_row = tax_table(psbin)[o,ncol(tax_table(psbin))],
#                            border_color = "grey60", gaps_row = cpx))
#   dev.off()
# }

################
####-------- DIVERGENCE PCoA Divergence based on Bray-Curtis distance or Jaccard distances
################

#####-------------- DIVERGENCE - JACCARD - Compute divergence for each subset
sample_data(gp)$bank = gsub('MeqITS','Meq',sample_data(gp)$bank)
#sample_data(gp)$bank = gsub('MeqCOI','Meq',sample_data(gp)$bank)
sample_data(gp)$bank = gsub('MS10ITS','MS10',sample_data(gp)$bank)
#sample_data(gp)$bank = gsub('MS10COI','MS10',sample_data(gp)$bank)
sample_data(gp)$bank = gsub('CPITS','CP',sample_data(gp)$bank)
#sample_data(gp)$bank = gsub('CPCOI','CP',sample_data(gp)$bank)

bk = unique(data.frame(sample_data(gp))$bank)
dmat = NULL

pdf(file='./PcoA_Jaccard_mocks.m.pdf',width = 14, height=8)
for(b in bk){
  
  ps = subset_samples(gp,bank == b)
  ps = tax_glom(ps,taxrank='species',NArm=F)
  ps = filter_taxa(ps, function(x) sum(x) > 0, TRUE)
  ps = prune_samples(sample_sums(ps) > 0, ps)
  psbin <- transform_sample_counts(ps, function(x) ifelse(x>0,1,0))
  
  ## MDS Jaccard
  out.jac.bin <- ordinate(psbin, method = "PCoA", distance = "jaccard")
  evals <- out.jac.bin$values$Eigenvalues
  
  ## Method
  p = plot_ordination(psbin, out.jac.bin, 
                      color = "method", shape  = "barcode") +
    labs(col = "Pipeline") + 
    geom_point(size = 5, alpha = .4) +
    #coord_fixed(sqrt(evals[2] / evals[1])) + 
    ggtitle(paste0('PCoA - Jaccard - ', b)) + theme(legend.position = 'bottom')
  print(p)
  
  ### Collect distance matrix
  d = vegan::vegdist(t(otu_table(ps)),'jaccard')
  d1 = reshape2::melt(as.matrix(d))
  d1$bank = b
  dmat = rbind(dmat,d1)
}
dev.off()

dmat.forplot = dmat[(dmat$Var2==dmat$bank | dmat$Var1==dmat$bank) & dmat$Var1!=dmat$Var2,]
lisV1 = dmat.forplot$Var1[dmat.forplot$Var2==dmat.forplot$bank] 
lisV2 = dmat.forplot$Var2[dmat.forplot$Var2==dmat.forplot$bank] 
lisidx = which(dmat.forplot$Var2==dmat.forplot$bank)
dmat.forplot$Var2[lisidx] = lisV1
dmat.forplot$Var1[lisidx] = lisV2

nfo = data.frame(sample_data(gp))
dmat.forplot$method = nfo$method[match(dmat.forplot$Var2,nfo$sample.id)]
dmat.forplot$barcode = nfo$barcode[match(dmat.forplot$Var2,nfo$sample.id)]
# dmat.forplot$Var2 = sapply(stringr::str_split(dmat.forplot$Var2,"COI"),function(x) x[1])
# dmat.forplot$Var2 = sapply(stringr::str_split(dmat.forplot$Var2,"ITS"),function(x) x[1])
# dmat.forplot$Var2[dmat.forplot$Var2=='']=dmat.forplot$method
dmat.forplot$nsp = 2
dmat.forplot$nsp[grep('Meq',dmat.forplot$bank)] = 11
dmat.forplot$nsp[grep('MS',dmat.forplot$bank)] = 11
dmat.forplot$nsp[grep('M1',dmat.forplot$bank)] = 5
dmat.forplot$nsp[grep('M2',dmat.forplot$bank)] = 5

dma.forplot.jaccard = dmat.forplot
head(dma.forplot.jaccard)
#    Var1                          Var2     value bank               method barcode nsp
# 13   CP mxee11_trunc200_BS-1_ITSCPITS 0.6086882   CP mxee11_trunc200_BS-1     ITS   2
# 26   CP mxee11_trunc217_BS-1_ITSCPITS 0.8506300   CP mxee11_trunc217_BS-1     ITS   2
# 39   CP mxee11_trunc200_BS16_ITSCPITS 0.5300906   CP mxee11_trunc200_BS16     ITS   2
# 52   CP mxee11_trunc217_BS16_ITSCPITS 0.8512106   CP mxee11_trunc217_BS16     ITS   2
# 65   CP mxee11_trunc200_BS32_ITSCPITS 0.5354576   CP mxee11_trunc200_BS32     ITS   2
# 78   CP mxee11_trunc217_BS32_ITSCPITS 0.6744887   CP mxee11_trunc217_BS32     ITS   2

#### Divergence vs. bank complexity
p.div.coi = ggplot(dmat.forplot[c(grep('COI',dmat.forplot$barcode),
                                  grep('itscox1',dmat.forplot$barcode)),],
                   aes(x = factor(nsp), y = value, col = method)) +
  geom_point(size =4,alpha=.4,position = position_dodge(width = .4)) +
  xlab('N species') + ylab('JAC distance') +
  theme(text = element_text(size =14 )) +
  ggtitle('COI')

p.div.its = ggplot(dmat.forplot[c(grep('ITS',dmat.forplot$barcode),
                                  grep('itscox1',dmat.forplot$barcode)),],
                   aes(x = factor(nsp), y = value, col = method)) +
  geom_point(size =4,alpha=.4,position = position_dodge(width = .4)) + 
  xlab('N species') + ylab('JAC distance') +
  theme(text = element_text(size =14 )) + 
  ggtitle('ITS')


pdf(file='./DivergenceJaccard.m.pdf',width = 14,height=8)
multiplot(p.div.coi,p.div.its,cols = 1)
dev.off()

least_div_jac = dmat.forplot %>%
  group_by(bank, barcode) %>%
  filter(value == min(value)) ## filter yields all values, even if equal 

data.frame(unique(least_div_jac[order(least_div_jac$bank,least_div_jac$value),]))
#    Var1                            Var2       value bank                   method barcode nsp
# 1       CP      mxee25_trunc217_BS32_ITSCPITS 0.261907333      CP     mxee25_trunc217_BS32     ITS   2
# 2     CP12    clus99_B1_k10_w8_COICP12_NoFilt 0.576784081    CP12  clus99_B1_k10_w8_NoFilt     COI   2
# 3       M1         mxee11_trunc217_BS32_ITSM1 0.372529644      M1     mxee11_trunc217_BS32     ITS   5
# 4       M1        clus99_B1_k10_w8_COIM1_Filt 0.836210526      M1    clus99_B1_k10_w8_Filt     COI   5
# 5       M1       clus99_B1_k15_w10_COIM1_Filt 0.836210526      M1   clus99_B1_k15_w10_Filt     COI   5
# 6       M1        clus99_B2_k10_w8_COIM1_Filt 0.836210526      M1    clus99_B2_k10_w8_Filt     COI   5
# 7       M1       clus99_B2_k10_w10_COIM1_Filt 0.836210526      M1   clus99_B2_k10_w10_Filt     COI   5
# 8       M1       clus99_B2_k15_w10_COIM1_Filt 0.836210526      M1   clus99_B2_k15_w10_Filt     COI   5
# 9       M1       clus99_B4_k10_w10_COIM1_Filt 0.836210526      M1   clus99_B4_k10_w10_Filt     COI   5
# 10      M1        clus99_B4_k13_w8_COIM1_Filt 0.836210526      M1    clus99_B4_k13_w8_Filt     COI   5
# 11      M1       clus99_B4_k15_w10_COIM1_Filt 0.836210526      M1   clus99_B4_k15_w10_Filt     COI   5
# 12     M11        mxee11_trunc217_BS32_ITSM11 0.409917355     M11     mxee11_trunc217_BS32     ITS   5
# 13     M11      clus99_B4_k10_w10_COIM11_Filt 0.836210526     M11   clus99_B4_k10_w10_Filt     COI   5
# 14      M2         mxee11_trunc200_BS-1_ITSM2 0.507641594      M2     mxee11_trunc200_BS-1     ITS   5
# 15      M2     clus99_B2_k10_w10_COIM2_NoFilt 0.756735621      M2 clus99_B2_k10_w10_NoFilt     COI   5
# 16     M21        mxee11_trunc200_BS-1_ITSM21 0.505526898     M21     mxee11_trunc200_BS-1     ITS   5
# 17     M21     clus99_B4_k15_w8_COIM21_NoFilt 0.787963795     M21  clus99_B4_k15_w8_NoFilt     COI   5
# 18      M3         mxee25_trunc217_BS32_ITSM3 0.182962046      M3     mxee25_trunc217_BS32     ITS   2
# 19      M3      clus99_B4_k10_w8_COIM3_NoFilt 0.400109901      M3  clus99_B4_k10_w8_NoFilt     COI   2
# 20     M31        mxee25_trunc217_BS32_ITSM31 0.085340262     M31     mxee25_trunc217_BS32     ITS   2
# 21      M4         mxee25_trunc217_BS32_ITSM4 0.037646176      M4     mxee25_trunc217_BS32     ITS   2
# 22      M4     clus99_B1_k13_w10_COIM4_NoFilt 0.355267288      M4 clus99_B1_k13_w10_NoFilt     COI   2
# 23     M41        mxee25_trunc217_BS32_ITSM41 0.052494680     M41     mxee25_trunc217_BS32     ITS   2
# 24      M5     clus99_B2_k15_w10_COIM5_NoFilt 0.006381429      M5 clus99_B2_k15_w10_NoFilt     COI   2
# 25      M5         mxee25_trunc217_BS32_ITSM5 0.255739530      M5     mxee25_trunc217_BS32     ITS   2
# 26     M51        mxee25_trunc217_BS32_ITSM51 0.263524565     M51     mxee25_trunc217_BS32     ITS   2
# 27     Meq     mxee25_trunc217_BS32_ITSMeqITS 0.499035456     Meq     mxee25_trunc217_BS32     ITS  11
# 28     Meq      clus99_B1_k10_w10_COIMeq_Filt 0.800000000     Meq   clus99_B1_k10_w10_Filt     COI  11
# 29     Meq      clus99_B4_k10_w10_COIMeq_Filt 0.800000000     Meq   clus99_B4_k10_w10_Filt     COI  11
# 30  MeqC12 clus99_B2_k10_w10_COIMeqC12_NoFilt 0.791646640  MeqC12 clus99_B2_k10_w10_NoFilt     COI  11
# 31    MS10     clus99_B4_k10_w10_COIMS10_Filt 0.544176463    MS10   clus99_B4_k10_w10_Filt     COI  11
# 32    MS10    mxee11_trunc200_BS-1_ITSMS10ITS 0.768850029    MS10     mxee11_trunc200_BS-1     ITS  11
# 33 MS10C12 clus99_B2_k13_w8_COIMS10C12_NoFilt 0.790317739 MS10C12  clus99_B2_k13_w8_NoFilt     COI  11

rm(dmat.forplot)

#####-------------- DIVERGENCE - BRAY-CURTIS - Compute divergence for each subset
bk = unique(data.frame(sample_data(gp))$bank)
dmat = NULL

pdf(file='./PcoA_Bray_mocks.m.pdf',width = 14, height=8)
for(b in bk){
  
  ps = subset_samples(gp,bank == b)
  ps = tax_glom(ps,taxrank='species',NArm=F)
  ps = filter_taxa(ps, function(x) sum(x) > 0, TRUE)
  ps = prune_samples(sample_sums(ps) > 0, ps) ## for low complexity communities
  pslog <- transform_sample_counts(ps, function(x) log(1 + x))
  
  ## MDS Bray
  out.bra.log <- ordinate(pslog, method = "MDS", distance = "bray")
  evals <- out.bra.log$values$Eigenvalues
  
  ## Method
  p = plot_ordination(pslog, out.bra.log, 
                      color = "method", shape  = "barcode") +
    labs(col = "Pipeline") + 
    geom_point(size = 5, alpha = .4) +
    #coord_fixed(sqrt(evals[2] / evals[1])) + 
    ggtitle(paste0('PCoA - Bray - ', b)) + theme(legend.position = 'bottom')
  print(p)
  
  ### Collect distance matrix
  d = vegan::vegdist(t(otu_table(ps)),'bray')
  d1 = reshape2::melt(as.matrix(d))
  d1$bank = b
  dmat = rbind(dmat,d1)
}
dev.off()


dmat.forplot = dmat[(dmat$Var2==dmat$bank | dmat$Var1==dmat$bank) & dmat$Var1!=dmat$Var2,]
lisV1 = dmat.forplot$Var1[dmat.forplot$Var2==dmat.forplot$bank] 
lisV2 = dmat.forplot$Var2[dmat.forplot$Var2==dmat.forplot$bank] 
lisidx = which(dmat.forplot$Var2==dmat.forplot$bank)
dmat.forplot$Var2[lisidx] = lisV1
dmat.forplot$Var1[lisidx] = lisV2

nfo = data.frame(sample_data(gp))
dmat.forplot$method = nfo$method[match(dmat.forplot$Var2,nfo$sample.id)]
dmat.forplot$barcode = nfo$barcode[match(dmat.forplot$Var2,nfo$sample.id)]
# dmat.forplot$Var2 = sapply(stringr::str_split(dmat.forplot$Var2,"COI"),function(x) x[1])
# dmat.forplot$Var2 = sapply(stringr::str_split(dmat.forplot$Var2,"ITS"),function(x) x[1])
# dmat.forplot$Var2[dmat.forplot$Var2=='']=dmat.forplot$method
dmat.forplot$nsp = 2
dmat.forplot$nsp[grep('Meq',dmat.forplot$bank)] = 11
dmat.forplot$nsp[grep('MS',dmat.forplot$bank)] = 11
dmat.forplot$nsp[grep('M1',dmat.forplot$bank)] = 5
dmat.forplot$nsp[grep('M2',dmat.forplot$bank)] = 5

#### Find the closest representation of the species abundance matrix
dma.forplot.bray = dmat.forplot
least_div_bray = dmat.forplot %>%
  group_by(bank, barcode) %>%
  filter(value == min(value)) ## filter yields all values, even if equal 
data.frame(unique(least_div_bray[order(least_div_bray$bank,least_div_bray$value),]))
#       Var1                               Var2       value    bank                   method barcode nsp
# 1       CP      mxee25_trunc217_BS32_ITSCPITS 0.150686634      CP     mxee25_trunc217_BS32     ITS   2
# 2     CP12    clus99_B1_k10_w8_COICP12_NoFilt 0.405268149    CP12  clus99_B1_k10_w8_NoFilt     COI   2
# 3       M1         mxee11_trunc217_BS32_ITSM1 0.228901032      M1     mxee11_trunc217_BS32     ITS   5
# 4       M1        clus99_B1_k10_w8_COIM1_Filt 0.718523878      M1    clus99_B1_k10_w8_Filt     COI   5
# 5       M1       clus99_B1_k15_w10_COIM1_Filt 0.718523878      M1   clus99_B1_k15_w10_Filt     COI   5
# 6       M1        clus99_B2_k10_w8_COIM1_Filt 0.718523878      M1    clus99_B2_k10_w8_Filt     COI   5
# 7       M1       clus99_B2_k10_w10_COIM1_Filt 0.718523878      M1   clus99_B2_k10_w10_Filt     COI   5
# 8       M1       clus99_B2_k15_w10_COIM1_Filt 0.718523878      M1   clus99_B2_k15_w10_Filt     COI   5
# 9       M1       clus99_B4_k10_w10_COIM1_Filt 0.718523878      M1   clus99_B4_k10_w10_Filt     COI   5
# 10      M1        clus99_B4_k13_w8_COIM1_Filt 0.718523878      M1    clus99_B4_k13_w8_Filt     COI   5
# 11      M1       clus99_B4_k15_w10_COIM1_Filt 0.718523878      M1   clus99_B4_k15_w10_Filt     COI   5
# 12     M11        mxee11_trunc217_BS32_ITSM11 0.257796258     M11     mxee11_trunc217_BS32     ITS   5
# 13     M11      clus99_B4_k10_w10_COIM11_Filt 0.718523878     M11   clus99_B4_k10_w10_Filt     COI   5
# 14      M2         mxee11_trunc200_BS-1_ITSM2 0.340160643      M2     mxee11_trunc200_BS-1     ITS   5
# 15      M2     clus99_B2_k10_w10_COIM2_NoFilt 0.608668304      M2 clus99_B2_k10_w10_NoFilt     COI   5
# 16     M21        mxee11_trunc200_BS-1_ITSM21 0.338264300     M21     mxee11_trunc200_BS-1     ITS   5
# 17     M21     clus99_B4_k15_w8_COIM21_NoFilt 0.650115724     M21  clus99_B4_k15_w8_NoFilt     COI   5
# 18      M3         mxee25_trunc217_BS32_ITSM3 0.100692474      M3     mxee25_trunc217_BS32     ITS   2
# 19      M3      clus99_B4_k10_w8_COIM3_NoFilt 0.250085866      M3  clus99_B4_k10_w8_NoFilt     COI   2
# 20     M31        mxee25_trunc217_BS32_ITSM31 0.044572025     M31     mxee25_trunc217_BS32     ITS   2
# 21      M4         mxee25_trunc217_BS32_ITSM4 0.019184194      M4     mxee25_trunc217_BS32     ITS   2
# 22      M4     clus99_B1_k13_w10_COIM4_NoFilt 0.216003053      M4 clus99_B1_k13_w10_NoFilt     COI   2
# 23     M41        mxee25_trunc217_BS32_ITSM41 0.026954832     M41     mxee25_trunc217_BS32     ITS   2
# 24      M5     clus99_B2_k15_w10_COIM5_NoFilt 0.003200928      M5 clus99_B2_k15_w10_NoFilt     COI   2
# 25      M5         mxee25_trunc217_BS32_ITSM5 0.146617741      M5     mxee25_trunc217_BS32     ITS   2
# 26     M51        mxee25_trunc217_BS32_ITSM51 0.151758303     M51     mxee25_trunc217_BS32     ITS   2
# 27     Meq     mxee25_trunc217_BS32_ITSMeqITS 0.332476511     Meq     mxee25_trunc217_BS32     ITS  11
# 28     Meq      clus99_B1_k10_w10_COIMeq_Filt 0.666666667     Meq   clus99_B1_k10_w10_Filt     COI  11
# 29     Meq      clus99_B4_k10_w10_COIMeq_Filt 0.666666667     Meq   clus99_B4_k10_w10_Filt     COI  11
# 30  MeqC12 clus99_B2_k10_w10_COIMeqC12_NoFilt 0.655144981  MeqC12 clus99_B2_k10_w10_NoFilt     COI  11
# 31    MS10     clus99_B4_k10_w10_COIMS10_Filt 0.373792874    MS10   clus99_B4_k10_w10_Filt     COI  11
# 32    MS10    mxee11_trunc200_BS-1_ITSMS10ITS 0.624497460    MS10     mxee11_trunc200_BS-1     ITS  11
# 33 MS10C12 clus99_B2_k13_w8_COIMS10C12_NoFilt 0.653326715 MS10C12  clus99_B2_k13_w8_NoFilt     COI  11


#### Divergence vs. bank complexity
p.div.coi = ggplot(dmat.forplot[c(grep('COI',dmat.forplot$barcode),grep('itscox1',dmat.forplot$barcode)),],
       aes(x = factor(nsp), y = value, col = method)) +
  geom_point(size =4,alpha=.4,position = position_dodge(width = .4)) +
  xlab('N species') + ylab('BC distance') +
  theme(text = element_text(size =14 )) +
  ggtitle('COI')

p.div.its = ggplot(dmat.forplot[c(grep('ITS',dmat.forplot$barcode),grep('itscox1',dmat.forplot$barcode)),],
         aes(x = factor(nsp), y = value, col = method)) +
  geom_point(size =4,alpha=.4,position = position_dodge(width = .4)) + 
  xlab('N species') + ylab('BC distance') +
  theme(text = element_text(size =14 )) + 
  ggtitle('ITS')

source('~/multiplot.R')
pdf(file='./DivergenceBrayCurtis.m.pdf')
multiplot(p.div.coi,
          p.div.its,cols = 1)
dev.off()

######################
####-------- TP / FP
######################

mstot = NULL
abutot = NULL

for(b in bk){
  
  ps = subset_samples(gp,bank == b) ## extract bank-related otu table
  ps = tax_glom(ps,taxrank='species',NArm=F)
  
  bin = data.frame(ifelse(otu_table(ps)>0,1,0)) ## convert to binary
  mstat = NULL
  
  colist = which(!(colnames(bin) %in% mms))
  n = 0
  
  ref = match(b,colnames(bin))
  
  for(i in colist){
    n = n+1
    mstat$bank[n] = b
    mstat$samp[n] = colnames(bin)[i]
    mstat$rich[n] = sum(bin[,i])
    mstat$tp[n] = length(which(bin[,i]==bin[,ref] & bin[,ref]==1))
    mstat$fp[n] = length(which(bin[,i]!=bin[,ref] & bin[,ref]==0))
    mstat$tn[n] = length(which(bin[,i]==bin[,ref] & bin[,ref]==0))
    mstat$fn[n] = length(which(bin[,i]!=bin[,ref] & bin[,ref]==1))
    mstat$recall[n] = mstat$tp[n]/(mstat$tp[n] + mstat$fn[n]) ## %True positive among all truly positives
    mstat$precision[n] = mstat$tp[n]/(mstat$tp[n] + mstat$fp[n]) ## %True positive among all found positives
    mstat$f1s[n] = 2*mstat$recall[n]*mstat$precision[n]/(mstat$recall[n] + mstat$precision[n])
    mstat$tpr[n] = mstat$tp[n]/(mstat$tp[n] + mstat$fn[n])
    mstat$fpr[n] = mstat$fp[n]/(mstat$fp[n] + mstat$tn[n])
    mstat$tnr[n] = mstat$tn[n]/(mstat$tn[n] + mstat$fp[n])
    mstat$fnr[n] = mstat$fn[n]/(mstat$fn[n] + mstat$p[n])
    
  }
  mstat = data.frame(mstat)
  mstot = rbind(mstot,mstat)
  
  # otu_count = data.frame(otu_table(ps))
  # df = reshape2::melt(otu_count,c(b))
  # colnames(df)[1] = 'mock'
  # df$bank = b
  # abutot = rbind(abutot,df)
}

mstot = data.frame(mstot)
head(mstot)
#     bank                          samp rich tp fp tn fn recall precision       f1s tpr  fpr  tnr fnr
# 1   CP mxee11_trunc200_BS.1_ITSCPITS    4  2  2 18  0    1.0      0.50 0.6666667 1.0 0.10 0.90 0.0
# 2   CP mxee11_trunc217_BS.1_ITSCPITS    4  1  3 17  1    0.5      0.25 0.3333333 0.5 0.15 0.85 0.8
# 3   CP mxee11_trunc200_BS16_ITSCPITS    4  2  2 18  0    1.0      0.50 0.6666667 1.0 0.10 0.90 0.0
# 4   CP mxee11_trunc217_BS16_ITSCPITS    4  1  3 17  1    0.5      0.25 0.3333333 0.5 0.15 0.85 0.8
# 5   CP mxee11_trunc200_BS32_ITSCPITS    4  2  2 18  0    1.0      0.50 0.6666667 1.0 0.10 0.90 0.0
# 6   CP mxee11_trunc217_BS32_ITSCPITS    4  1  3 17  1    0.5      0.25 0.3333333 0.5 0.15 0.85 0.8

mstot$samp = gsub('\\.','-',mstot$samp)
mstot$method = nfo$method[match(mstot$samp,nfo$sample.id)]
mstot$barcode = nfo$barcode[match(mstot$samp,nfo$sample.id)]
mstot0 = mstot
head(mstot0)
# bank                          samp rich tp fp tn fn recall precision       f1s tpr  fpr  tnr       fnr               method barcode
# 1   CP mxee11_trunc200_BS-1_ITSCPITS    4  2  2 18  0    1.0      0.50 0.6666667 1.0 0.10 0.90 0.0000000 mxee11_trunc200_BS-1     ITS
# 2   CP mxee11_trunc217_BS-1_ITSCPITS    5  1  4 16  1    0.5      0.20 0.6666667 0.5 0.20 0.80 0.8333333 mxee11_trunc217_BS-1     ITS
# 3   CP mxee11_trunc200_BS16_ITSCPITS    4  2  2 18  0    1.0      0.50 0.6666667 1.0 0.10 0.90 0.0000000 mxee11_trunc200_BS16     ITS
# 4   CP mxee11_trunc217_BS16_ITSCPITS    4  1  3 17  1    0.5      0.25 0.6666667 0.5 0.15 0.85 0.8000000 mxee11_trunc217_BS16     ITS
# 5   CP mxee11_trunc200_BS32_ITSCPITS    4  2  2 18  0    1.0      0.50 0.6666667 1.0 0.10 0.90 0.0000000 mxee11_trunc200_BS32     ITS
# 6   CP mxee11_trunc217_BS32_ITSCPITS    4  1  3 17  1    0.5      0.25 0.6666667 0.5 0.15 0.85 0.8000000 mxee11_trunc217_BS32     ITS
# complex
# 1       2
# 2       2
# 3       2
# 4       2
# 5       2
# 6       2

mstot0$complex = 2
mstot0$complex[mstot0$bank %in% c('Meq','MS10',"MeqC12","MS10C12")] = 5
mstot0$complex[mstot0$bank %in% c("M1","M11","M2","M21")] = 11

mstot = reshape2::melt(mstot0,c('bank','samp','method','barcode','complex'))
head(mstot)
# bank                          samp               method barcode complex variable value
# 1   CP mxee11_trunc200_BS-1_ITSCPITS mxee11_trunc200_BS-1     ITS       2     rich     4
# 2   CP mxee11_trunc217_BS-1_ITSCPITS mxee11_trunc217_BS-1     ITS       2     rich     5
# 3   CP mxee11_trunc200_BS16_ITSCPITS mxee11_trunc200_BS16     ITS       2     rich     4
# 4   CP mxee11_trunc217_BS16_ITSCPITS mxee11_trunc217_BS16     ITS       2     rich     4
# 5   CP mxee11_trunc200_BS32_ITSCPITS mxee11_trunc200_BS32     ITS       2     rich     4
# 6   CP mxee11_trunc217_BS32_ITSCPITS mxee11_trunc217_BS32     ITS       2     rich     4

# ### TPR
# 
# tpr = data.frame(mstot[,c('barcode','bank','method','tpr')] %>% 
#                    group_by(barcode,bank,method) %>%
#                    filter(tpr == max(tpr)))
# count.tpr = data.frame(table(tpr$method,tpr$bank,tpr$barcode))
# count.tpr = count.tpr[count.tpr$Freq==1,]
# colnames(count.tpr)[4]='tpr'
# 
# ###  FPR
# fpr = data.frame(mstot[,c('barcode','bank','method','fpr')]) %>% 
#   group_by(barcode,bank,method) %>%
#   filter(fpr == min(fpr))
# count.fpr = data.frame(table(fpr$method,fpr$bank,fpr$barcode))
# count.fpr = count.fpr[count.fpr$Freq==1,]
# colnames(count.fpr)[4]='fpr'
# 
# ## Recall ; TP / TP + FN
# recall = data.frame(mstot[,c('barcode','bank','method','recall')] %>% 
#                    group_by(barcode,bank,method) %>%
#                    filter(recall == max(recall)))
# count.reca = data.frame(table(recall$method,recall$bank,recall$barcode))
# count.reca = count.reca[count.reca$Freq==1,]
# colnames(count.reca)[4]='Recall'
# 
# ## Precision ; TP / TP + FP
# precision = data.frame(mstot[,c('barcode','bank','method','precision')] %>% 
#                          group_by(barcode,bank,method) %>%
#                          filter(precision == max(precision)))
# count.prec = data.frame(table(precision$method,precision$bank,precision$barcode))
# count.prec = count.prec[count.prec$Freq==1,]
# colnames(count.prec)[4]='Precision'
# 
# df = merge(precision, recall, by = c('barcode','bank','method'))
# df$complex = 2
# df$complex[df$bank %in% c('Meq','MS10',"MeqC12","MS10C12")]=5
# df$complex[df$bank %in% c("M1","M11","M2","M21")]=11
# 
# ## F1-score
# df = df %>%
#   mutate(f1s = 2*(recall*precision)/(recall+precision)) 
# 
# d = df %>%
#   group_by(complex, bank, barcode) %>%
#   slice_max(f1s)

### Set missing cases to 0 ; corresponds to cases where filtering removed all data
mstot0$f1s[is.na(mstot0$f1s)] = 0

pdf(file = './F1Score.pdf',width = 14, height = 8)
ggplot(mstot0,aes(x = method, y = f1s, fill = barcode)) +
  geom_boxplot(alpha=.6) +
  #facet_wrap(~ complex) + 
  coord_flip() +theme(legend.position = 'bottom')
dev.off()

# pdf(file='./Recall.vs.Precision.pdf',width=14,height=8)
# ggplot(df[substr(df$method,1,4)!='mxee' & 
#             !is.na(df$barcode) &
#             df$bank!='M31' &
#             substr(df$method,1,6)!='mxee25' & df$method!='usearch',],
#        aes(x = precision, y = recall,col = method)) +
#   geom_point(size = 4, alpha = 1, position = position_dodge(width=.1)) +
#   facet_wrap(~ paste0('Barcode: ',barcode)+ paste0('Complexity - ',complex, ' species') ,ncol=3)+
#   #theme_classic() + 
#   theme(legend.position = 'bottom',strip.background = element_blank())+ 
#   xlab('Precision') + ylab('Recall') +
#   scale_color_manual(values = viridis_pal(option = 'D')(6))
# dev.off()

### Effect of each parameter on f1s
reg.f1s.coi = mstot0[mstot0$barcode=='COI',]
reg.f1s.its = mstot0[mstot0$barcode=='ITS',]

shapiro.test(reg.f1s.coi$f1s)
#W = 0.88341, p-value = 2.775e-16
shapiro.test(reg.f1s.its$f1s)
#W = 0.89284, p-value = 3.154e-09

### F1-score - COI
reg.f1s.coi$B = sapply(stringr::str_split(reg.f1s.coi$method,"_"),function(x) x[2])
reg.f1s.coi$k = sapply(stringr::str_split(reg.f1s.coi$method,"_"),function(x) x[3])
reg.f1s.coi$w = sapply(stringr::str_split(reg.f1s.coi$method,"_"),function(x) x[4])
reg.f1s.coi$MQ = sapply(stringr::str_split(reg.f1s.coi$method,"_"),function(x) x[5])

mf1s.coi1 = lm(f1s ~ B + k + w + MQ, data = reg.f1s.coi)
s = MASS::stepAIC(mf1s.coi1)
s$anova
# Final Model:
#   f1s ~ k + MQ
# 
# 
# Step Df   Deviance Resid. Df Resid. Dev       AIC
# 1                          369   8.007946 -1433.282
# 2  - B  2 0.05858852       371   8.066534 -1434.541
# 3  - w  1 0.02632911       372   8.092864 -1435.316

mf1s.coi2 = lm(f1s ~ k + MQ, data = reg.f1s.coi)
summary(mf1s.coi2)
# Call:
#   lm(formula = f1s ~ k + MQ, data = reg.f1s.coi)
# 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -0.49239 -0.05234  0.04000  0.07904  0.27165 
# 
# Coefficients:
#   Estimate Std. Error t value Pr(>|t|)    
# (Intercept)  0.49239    0.01589  30.990   <2e-16 ***
# kk13        -0.01651    0.01873  -0.881   0.3788    
# kk15        -0.04816    0.01855  -2.596   0.0098 ** 
# MQNoFilt     0.28411    0.01537  18.480   <2e-16 ***
#   ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.1475 on 372 degrees of freedom
# Multiple R-squared:  0.4846,	Adjusted R-squared:  0.4804 
# F-statistic: 116.6 on 3 and 372 DF,  p-value: < 2.2e-16

##### B4 (default) & w10 (default) : k and MQ are most important factors 
##### k10 and MQ=0 maximizes F1-score

### F1-score - ITS
reg.f1s.its$mxee = sapply(stringr::str_split(reg.f1s.its$method,"_"),function(x) x[1])
reg.f1s.its$trunc = sapply(stringr::str_split(reg.f1s.its$method,"_"),function(x) x[2])
reg.f1s.its$BS = sapply(stringr::str_split(reg.f1s.its$method,"_"),function(x) x[3])

mf1s.its1 = lm(f1s ~ mxee + trunc + BS, data = reg.f1s.its)
s = MASS::stepAIC(mf1s.its1)
s$anova
# Stepwise Model Path 
# Analysis of Deviance Table
# 
# Initial Model:
#   f1s ~ mxee + trunc + BS
# 
# Final Model:
#   f1s ~ mxee + trunc
# 
# 
# Step Df    Deviance Resid. Df Resid. Dev       AIC
# 1                          151   4.203793 -553.7635
# 2 - BS  2 0.01146614       153   4.215259 -557.3386

mf1s.its2 = lm(f1s ~  mxee + trunc , data = reg.f1s.its)
summary(mf1s.its2)
# lm(formula = f1s ~ mxee + trunc, data = reg.f1s.its)
# 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -0.41446 -0.08112  0.01103  0.14437  0.34437 
# 
# Coefficients:
#               Estimate Std. Error t value Pr(>|t|)    
# (Intercept)    0.68568    0.02302  29.789  < 2e-16 ***
# mxeemxee25     0.06211    0.02658   2.337 0.020748 *  
# trunctrunc217 -0.09216    0.02658  -3.467 0.000683 ***
#   ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.166 on 153 degrees of freedom
# Multiple R-squared:  0.1025,	Adjusted R-squared:  0.09082 
# F-statistic: 8.741 on 2 and 153 DF,  p-value: 0.0002543

##### mxee11 with truncL of 200 bp gives the best representation in terms of species/pab for the most complex communities
##### This is despite better performances of mxee25 for divergence
## BS does not affect F1-score 

##############################
####-------- Divergence
##############################

head(dma.forplot.jaccard)
#    Var1                   Var2     value bank         method barcode nsp
# 9  CP12     dada2_mxe1_COICP12 0.8214349 CP12     dada2_mxe1     COI   2
# 18 CP12     dada2_mxe2_COICP12 0.8244786 CP12     dada2_mxe2     COI   2
# 27 CP12     dada2_mxe3_COICP12 0.8251127 CP12     dada2_mxe3     COI   2
# 36 CP12     dada2_mxe5_COICP12 0.8255420 CP12     dada2_mxe5     COI   2
# 45 CP12 dada2_mxerelax_COICP12 1.0000000 CP12 dada2_mxerelax     COI   2
# 54 CP12           COICP12_Filt 1.0000000 CP12   minimap_Filt     COI   2
colnames(dma.forplot.jaccard)[c(2,3)]=c('samp','jacc')
#dma.forplot.jaccard$samp = gsub('BS-1','BS.1',dma.forplot.jaccard$samp)

head(dma.forplot.bray)
#    Var1                   Var2     value bank         method barcode nsp
# 9  CP12     dada2_mxe1_COICP12 0.6969788 CP12     dada2_mxe1     COI   2
# 18 CP12     dada2_mxe2_COICP12 0.7013726 CP12     dada2_mxe2     COI   2
# 27 CP12     dada2_mxe3_COICP12 0.7022910 CP12     dada2_mxe3     COI   2
# 36 CP12     dada2_mxe5_COICP12 0.7029132 CP12     dada2_mxe5     COI   2
# 45 CP12 dada2_mxerelax_COICP12 1.0000000 CP12 dada2_mxerelax     COI   2
# 54 CP12           COICP12_Filt 1.0000000 CP12   minimap_Filt     COI   2
colnames(dma.forplot.bray)[c(2,3)]=c('samp','bray')
#dma.forplot.bray$samp = gsub('BS-1','BS.1',dma.forplot.bray$samp)

head(mstot0)
# bank                          samp rich tp fp tn fn recall precision       f1s tpr  fpr  tnr       fnr               method barcode
# 1   CP mxee11_trunc200_BS-1_ITSCPITS    4  2  2 18  0    1.0      0.50 0.6666667 1.0 0.10 0.90 0.0000000 mxee11_trunc200_BS-1     ITS
# 2   CP mxee11_trunc217_BS-1_ITSCPITS    5  1  4 16  1    0.5      0.20 0.2857143 0.5 0.20 0.80 0.8333333 mxee11_trunc217_BS-1     ITS
# 3   CP mxee11_trunc200_BS16_ITSCPITS    4  2  2 18  0    1.0      0.50 0.6666667 1.0 0.10 0.90 0.0000000 mxee11_trunc200_BS16     ITS
# 4   CP mxee11_trunc217_BS16_ITSCPITS    4  1  3 17  1    0.5      0.25 0.3333333 0.5 0.15 0.85 0.8000000 mxee11_trunc217_BS16     ITS
# 5   CP mxee11_trunc200_BS32_ITSCPITS    4  2  2 18  0    1.0      0.50 0.6666667 1.0 0.10 0.90 0.0000000 mxee11_trunc200_BS32     ITS
# 6   CP mxee11_trunc217_BS32_ITSCPITS    4  1  3 17  1    0.5      0.25 0.3333333 0.5 0.15 0.85 0.8000000 mxee11_trunc217_BS32     ITS
# complex
# 1       2
# 2       2
# 3       2
# 4       2
# 5       2
# 6       2

####-- Format final evaluation table
## Add divergence with Bray-Curtis distance
final_eval_tab = unique(merge(mstot0,
                   unique(dma.forplot.bray[,c('samp','bray')]), by = 'samp'))

## Add divergence with Jaccard distance
final_eval_tab = unique(merge(final_eval_tab,
                   (dma.forplot.jaccard[,c('samp','jacc')]), by = 'samp'))
dim(final_eval_tab)
#[1] 532    19

final_eval_tab$complex = 2
final_eval_tab$complex[final_eval_tab$bank %in% c('Meq','MS10',"MeqC12","MS10C12")] = 5
final_eval_tab$complex[final_eval_tab$bank %in% c("M1","M11","M2","M21")] = 11

## Shorter final_eval for plot
final_eval = final_eval_tab[,c('samp','bank','f1s','method','barcode','bray','jacc','complex')]
final_eval = reshape2::melt(final_eval,c('samp','bank','method','barcode','complex'))
final_eval$barcode[is.na(final_eval$method)] = 'ITS'

### ITS-2

ggplot(final_eval[final_eval$barcode=='ITS',],aes(x = paste0(variable,complex),y = value, fill = factor(complex))) +
  geom_boxplot(alpha =.6) + ylab('') +
  facet_wrap(~ method,ncol = 3) + coord_flip() +
  theme(legend.position='none')

ggplot(final_eval[final_eval$barcode=='COI',],aes(x = paste0(variable,complex),y = value, fill = factor(complex))) +
  geom_boxplot(alpha =.6) + ylab('') +
  facet_wrap(~ method) + coord_flip() +
  theme(legend.position='none')

### Effect of the parameters on divergence on species relative abundance or presence/absence

## COI
div.bray.coi = final_eval[final_eval$barcode=='COI' & final_eval$variable=='bray',]
div.jacc.coi = final_eval[final_eval$barcode=='COI' & final_eval$variable=='jacc',]

div.bray.coi$B = sapply(stringr::str_split(div.bray.coi$method,"_"),function(x) x[2])
div.bray.coi$k = sapply(stringr::str_split(div.bray.coi$method,"_"),function(x) x[3])
div.bray.coi$w = sapply(stringr::str_split(div.bray.coi$method,"_"),function(x) x[4])
div.bray.coi$MQ = sapply(stringr::str_split(div.bray.coi$method,"_"),function(x) x[5])

mod.coi.bray = lm(value ~ B + k + w + MQ, data = div.bray.coi)
MASS::stepAIC(mod.coi.bray)$anova
# Stepwise Model Path 
# Analysis of Deviance Table
# 
# Initial Model:
#   value ~ B + k + w + MQ
# 
# Final Model:
#   value ~ MQ
# 
# 
# Step Df    Deviance Resid. Df Resid. Dev       AIC
# 1                           297   13.56977 -931.1917
# 2  - B  2 0.029501750       299   13.59927 -934.5315
# 3  - k  2 0.055588529       301   13.65486 -937.2914
# 4  - w  1 0.001568452       302   13.65643 -939.2564

summary(lm(value ~ MQ, data = div.bray.coi))
# Call:
#   lm(formula = value ~ MQ, data = div.bray.coi)
# 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -0.53888 -0.10728  0.00563  0.21551  0.27256 
# 
# Coefficients:
#   Estimate Std. Error t value Pr(>|t|)    
# (Intercept)  0.77395    0.01902  40.691   <2e-16 ***
#   MQNoFilt    -0.23186    0.02479  -9.354   <2e-16 ***

div.jacc.coi$B = sapply(stringr::str_split(div.jacc.coi$method,"_"),function(x) x[2])
div.jacc.coi$k = sapply(stringr::str_split(div.jacc.coi$method,"_"),function(x) x[3])
div.jacc.coi$w = sapply(stringr::str_split(div.jacc.coi$method,"_"),function(x) x[4])
div.jacc.coi$MQ = sapply(stringr::str_split(div.jacc.coi$method,"_"),function(x) x[5])

mod.coi.jacc = lm(value ~ B + k + w + MQ, data = div.jacc.coi)
MASS::stepAIC(mod.coi.jacc)$anova
# Initial Model:
#   value ~ B + k + w + MQ
# 
# Final Model:
#   value ~ MQ
# 
# 
# Step Df     Deviance Resid. Df Resid. Dev       AIC
# 1                            297   13.60663 -930.3670
# 2  - B  2 0.0118775962       299   13.61851 -934.1017
# 3  - k  2 0.0258505661       301   13.64436 -937.5252
# 4  - w  1 0.0008294408       302   13.64519 -939.5067

summary(lm(value ~ MQ, data = div.jacc.coi))
# Call:
#   lm(formula = value ~ MQ, data = div.jacc.coi)
# 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -0.67515 -0.06727  0.06320  0.11432  0.21632 
# 
# Coefficients:
#   Estimate Std. Error t value Pr(>|t|)    
# (Intercept)  0.88568    0.01546  57.288   <2e-16 ***
# MQNoFilt    -0.20415    0.02045  -9.985   <2e-16 ***
#   ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.1962 on 374 degrees of freedom
# Multiple R-squared:  0.2105,	Adjusted R-squared:  0.2084 
# F-statistic: 99.71 on 1 and 374 DF,  p-value: < 2.2e-16

## ITS
div.bray.its = final_eval[final_eval$barcode=='ITS' & final_eval$variable=='bray',]
div.bray.its$mxee = sapply(stringr::str_split(div.bray.its$method,"_"),function(x) x[1])
div.bray.its$trunc = sapply(stringr::str_split(div.bray.its$method,"_"),function(x) x[2])
div.bray.its$BS = sapply(stringr::str_split(div.bray.its$method,"_"),function(x) x[3])

mod.its.bray = lm(value ~ mxee + trunc + BS, data = div.bray.its)
MASS::stepAIC(mod.its.bray)$anova
# Stepwise Model Path 
# Analysis of Deviance Table
# 
# Initial Model:
#   value ~ mxee + trunc + BS
# 
# Final Model:
#   value ~ mxee + trunc + BS
# 
# 
# Step Df   Deviance Resid. Df Resid. Dev       AIC
# 1                         151   4.520015 -542.366

summary(lm(value ~ mxee + trunc + BS, data = div.bray.its))
# Call:
#   lm(formula = value ~ mxee + trunc + BS, data = div.bray.its)
# 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -0.36543 -0.12340 -0.01494  0.11594  0.45039 
# 
# Coefficients:
#                Estimate Std. Error t value Pr(>|t|)    
# (Intercept)    0.509711   0.030983  16.451  < 2e-16 ***
# mxeemxee25    -0.121971   0.027712  -4.401 2.02e-05 ***
# trunctrunc217  0.086044   0.027712   3.105  0.00227 ** 
# BSBS16         0.001953   0.033940   0.058  0.95418    
# BSBS32        -0.089171   0.033940  -2.627  0.00949 ** 
#   ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.1731 on 151 degrees of freedom
# Multiple R-squared:  0.2028,	Adjusted R-squared:  0.1817 
# F-statistic: 9.606 on 4 and 151 DF,  p-value: 6.014e-07

div.jacc.its = final_eval[final_eval$barcode=='ITS' & final_eval$variable=='jacc',]
div.jacc.its$mxee = sapply(stringr::str_split(div.jacc.its$method,"_"),function(x) x[1])
div.jacc.its$trunc = sapply(stringr::str_split(div.jacc.its$method,"_"),function(x) x[2])
div.jacc.its$BS = sapply(stringr::str_split(div.jacc.its$method,"_"),function(x) x[3])

mod.its.jacc = lm(value ~ mxee + trunc + BS, data = div.jacc.its)
MASS::stepAIC(mod.its.jacc)$anova
# Stepwise Model Path 
# Analysis of Deviance Table
# 
# Initial Model:
#   value ~ mxee + trunc + BS
# 
# Final Model:
#   value ~ mxee + trunc + BS
# 
# 
# Step Df Deviance Resid. Df Resid. Dev       AIC
# 1                        151   4.103872 -557.5163

summary(lm(value ~ mxee + trunc + BS, data = div.jacc.its))
# Call:
#   lm(formula = value ~ mxee + trunc + BS, data = div.jacc.its)
# 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -0.48077 -0.09628  0.00172  0.11082  0.34959 
# 
# Coefficients:
#                Estimate Std. Error t value Pr(>|t|)    
# (Intercept)    0.667920   0.029514  22.630  < 2e-16 ***
# mxeemxee25    -0.110003   0.026398  -4.167 5.18e-05 ***
# trunctrunc217  0.056194   0.026398   2.129  0.03490 *  
# BSBS16         0.001802   0.032331   0.056  0.95563    
# BSBS32        -0.095695   0.032331  -2.960  0.00358 ** 
#   ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.1649 on 151 degrees of freedom
# Multiple R-squared:  0.1829,	Adjusted R-squared:  0.1613 
# F-statistic:  8.45 on 4 and 151 DF,  p-value: 3.525e-06

### BS32 and mxee25 perform better overall 
### but this varies across community sizes (not significant)

aggregate(value ~ method + complex, FUN=mean, 
          data = div.bray.its[div.bray.its$trunc=='trunc200' & div.bray.its$BS=='BS32',])
#                 method complex     value
# 1 mxee11_trunc200_BS32       2 0.3734525
# 2 mxee25_trunc200_BS32       2 0.3624554
# 3 mxee11_trunc200_BS32       5 0.5043399
# 4 mxee25_trunc200_BS32       5 0.5095130
# 5 mxee11_trunc200_BS32      11 0.4138057
# 6 mxee25_trunc200_BS32      11 0.5137123

aggregate(value ~ method + complex, FUN=mean, 
          data = div.jacc.its[div.jacc.its$trunc=='trunc200' & div.jacc.its$BS=='BS32',])
#                 method complex     value
# 1 mxee11_trunc200_BS32       2 0.5339820
# 2 mxee25_trunc200_BS32       2 0.5233370
# 3 mxee11_trunc200_BS32       5 0.6619769
# 4 mxee25_trunc200_BS32       5 0.6667511
# 5 mxee11_trunc200_BS32      11 0.5833488
# 6 mxee25_trunc200_BS32      11 0.6774358

##############################
####-------- Alpha diversity for last comparison between dada2 methods
##############################
alpha_div <- estimate_richness(gp, split = TRUE, measure = c("Shannon","Simpson"))
alpha_div$sample.id <- rownames(alpha_div) %>%  as.factor()

alphaplot <- sample_data(gp) %>%
  unclass() %>%
  data.frame() %>%
  left_join(alpha_div, by = "sample.id") %>%
  reshape2::melt(measure.vars = c("Shannon","Simpson"),
                 variable.name = "diversity_measure",
                 value.name = "alpha_diversity")

alphaplot$method = relevel(factor(alphaplot$method),ref ='mock')
pdf(file='./AlphaDiversity.Shannon.m.pdf',width=14,height=8)
shannon_plot = ggplot(alphaplot[alphaplot$diversity_measure=='Shannon',]) +
  geom_point(aes(x = method, y = alpha_diversity,group = bank,
                 col = barcode), size = 4, alpha = .4, position = position_dodge(width = .5)) +
  scale_y_continuous(limits = c(0, 3), breaks = seq(0, 3, .5)) +
  # geom_line(aes(x = method, y = alpha_diversity,group = bank,
  #               col = bank), alpha = .4) + 
  #scale_color_brewer(palette = "Set2") +
  facet_wrap(~ bank) + 
  coord_flip() +
  labs(x = "Bank", y = "Shannon Diversity", color = "Pipeline") +
  theme(legend.position = 'bottom', text = element_text(size = 14)) 
print(shannon_plot)
dev.off()

pdf(file='./AlphaDiversity.Simpson.m.pdf',width=14,height=8)
simpson_plot = ggplot(alphaplot[alphaplot$diversity_measure=='Simpson',]) +
  geom_point(aes(x = method, y = alpha_diversity,group = bank,
                 col = barcode), size = 4, alpha = .4, 
             position = position_dodge(width = .5)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, .2)) +
  # geom_line(aes(x = method, y = alpha_diversity,group = bank,
  #               col = bank), alpha = .4) + 
  #scale_color_brewer(palette = "Set2") +
  facet_wrap(~ bank) + 
  coord_flip() +
  labs(x = "Bank", y = "Simpson Diversity", color = "Pipeline") +
  theme(legend.position = 'bottom', text = element_text(size = 14)) 
print(simpson_plot)
dev.off()

### Distance from truth

alpha_mock = alphaplot[alphaplot$barcode=='mock',c('bank','diversity_measure','alpha_diversity')]
colnames(alpha_mock)[3] = 'alpha_mock'

alpha_diff = merge(alphaplot,alpha_mock, by = c('bank','diversity_measure'))
alpha_diff$dif = alpha_diff$alpha_mock - alpha_diff$alpha_diversity

alpha_diff$complex = 2
alpha_diff$complex[alpha_diff$bank %in% c('Meq','MS10',"MeqC12","MS10C12")] = 5
alpha_diff$complex[alpha_diff$bank %in% c("M1","M11","M2","M21")] = 11


ggplot(alpha_diff[alpha_diff$barcode=='COI',],
       aes(x = diversity_measure,y = dif, fill = factor(complex))) +
  geom_hline(yintercept = 0,col='darkgrey') +
  geom_boxplot(alpha =.6) + 
  facet_wrap(~ method) + 
  theme(legend.position='bottom')

ggplot(alpha_diff[alpha_diff$barcode=='ITS',],
       aes(x = diversity_measure,y = dif, fill = factor(complex))) +
  geom_hline(yintercept = 0,col='darkgrey') +
  geom_boxplot(alpha =.6) + 
  facet_wrap(~ method) + 
  theme(legend.position='bottom')

head(alpha_diff)
# bank diversity_measure                     sample.id               method barcode alpha_diversity alpha_mock        dif complex
# 1   CP           Shannon mxee11_trunc200_BS-1_ITSCPITS mxee11_trunc200_BS-1     ITS       1.1180338  0.6931472 -0.4248866       2
# 2   CP           Shannon mxee25_trunc200_BS32_ITSCPITS mxee25_trunc200_BS32     ITS       1.1174015  0.6931472 -0.4242543       2
# 3   CP           Shannon mxee25_trunc217_BS32_ITSCPITS mxee25_trunc217_BS32     ITS       1.1406386  0.6931472 -0.4474914       2
# 4   CP           Shannon                            CP                 mock    mock       0.6931472  0.6931472  0.0000000       2
# 5   CP           Shannon mxee11_trunc200_BS32_ITSCPITS mxee11_trunc200_BS32     ITS       0.8690987  0.6931472 -0.1759516       2
# 6   CP           Shannon mxee11_trunc217_BS-1_ITSCPITS mxee11_trunc217_BS-1     ITS       0.8268761  0.6931472 -0.1337289       2

### Alpha COI
alpha.coi = alpha_diff[alpha_diff$barcode=='COI',]
alpha.coi$B = sapply(stringr::str_split(alpha.coi$method,"_"),function(x) x[2])
alpha.coi$k = sapply(stringr::str_split(alpha.coi$method,"_"),function(x) x[3])
alpha.coi$w = sapply(stringr::str_split(alpha.coi$method,"_"),function(x) x[4])
alpha.coi$MQ = sapply(stringr::str_split(alpha.coi$method,"_"),function(x) x[5])

## Shannon COI
MASS::stepAIC(lm(dif ~ B + k + w + MQ,data = alpha.coi[alpha.coi$diversity_measure=='Shannon',]))$anova
# Stepwise Model Path 
# Analysis of Deviance Table
# 
# Initial Model:
#   dif ~ B + k + w + MQ
# 
# Final Model:
#   dif ~ MQ
# 
# 
# Step Df   Deviance Resid. Df Resid. Dev       AIC
# 1                          369   122.4413 -407.8561
# 2  - B  2 0.06169325       371   122.5030 -411.6667
# 3  - k  2 0.16752386       373   122.6705 -415.1528
# 4  - w  1 0.12594307       374   122.7964 -416.7670

summary(lm(dif ~ MQ, data = alpha.coi[alpha.coi$diversity_measure=='Shannon',]))
# lm(formula = dif ~ MQ, data = alpha.coi[alpha.coi$diversity_measure == 
#                                           "Shannon", ])
# 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -0.88779 -0.52367  0.06102  0.23785  1.23170 
# 
# Coefficients:
#               Estimate Std. Error t value Pr(>|t|)    
#   (Intercept)  1.10947    0.04516  24.568  < 2e-16 ***
#   MQNoFilt    -0.40475    0.05972  -6.777 4.78e-11 ***
#   ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.573 on 374 degrees of freedom
# Multiple R-squared:  0.1094,	Adjusted R-squared:  0.107 
# F-statistic: 45.93 on 1 and 374 DF,  p-value: 4.776e-11

## Simpson COI
MASS::stepAIC(lm(dif ~ B + k + w + MQ,data = alpha.coi[alpha.coi$diversity_measure=='Simpson',]))$anova
# Stepwise Model Path 
# Analysis of Deviance Table
# 
# Initial Model:
#   dif ~ B + k + w + MQ
# 
# Final Model:
#   dif ~ MQ
# 
# 
# Step Df   Deviance Resid. Df Resid. Dev       AIC
# 1                          369   19.32054 -1102.126
# 2  - B  2 0.04541175       371   19.36595 -1105.243
# 3  - k  2 0.05275498       373   19.41871 -1108.220
# 4  - w  1 0.03160941       374   19.45032 -1109.609

summary(lm(dif ~ MQ, data = alpha.coi[alpha.coi$diversity_measure=='Simpson',]))
# lm(formula = dif ~ MQ, data = alpha.coi[alpha.coi$diversity_measure == 
#                                           "Simpson", ])
# 
# Residuals:
#   Min      1Q  Median      3Q     Max 
# -0.4239 -0.1838 -0.0331  0.1643  0.4587 
# 
# Coefficients:
#   Estimate Std. Error t value Pr(>|t|)    
# (Intercept)  0.43636    0.01797  24.279  < 2e-16 ***
#   MQNoFilt    -0.13747    0.02377  -5.784 1.54e-08 ***
#   ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.228 on 374 degrees of freedom
# Multiple R-squared:  0.08211,	Adjusted R-squared:  0.07965 
# F-statistic: 33.45 on 1 and 374 DF,  p-value: 1.542e-08

### Alpha ITS
## Shannon ITS
alpha.its = alpha_diff[alpha_diff$barcode=='ITS',]
alpha.its$mxee = sapply(stringr::str_split(alpha.its$method,"_"),function(x) x[1])
alpha.its$trunc = sapply(stringr::str_split(alpha.its$method,"_"),function(x) x[2])
alpha.its$BS = sapply(stringr::str_split(alpha.its$method,"_"),function(x) x[3])

MASS::stepAIC(lm(dif ~ mxee + trunc + BS ,
                 data = alpha.its[alpha.its$diversity_measure=='Shannon',]))$anova
# Initial Model:
#   dif ~ mxee + trunc + BS
# 
# Final Model:
#   dif ~ mxee
# 
# 
# Step Df   Deviance Resid. Df Resid. Dev       AIC
# 1                             151   11.44930 -397.4607
# 2 - trunc  1 0.01164659       152   11.46094 -399.3021
# 3    - BS  2 0.18426600       154   11.64521 -400.8140

summary(lm(dif ~ mxee  ,data = alpha.its[alpha.its$diversity_measure=='Shannon',]))
# Call:
#   lm(formula = dif ~ mxee, data = alpha.its[alpha.its$diversity_measure == 
#                                               "Shannon", ])
# 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -0.70096 -0.19691  0.03841  0.23951  0.52847 
# 
# Coefficients:
#               Estimate Std. Error t value Pr(>|t|)    
#   (Intercept) -0.17117    0.03241  -5.281 4.31e-07 ***
#   mxeemxee25   0.07457    0.04584   1.627    0.106    
# ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.2863 on 154 degrees of freedom
# Multiple R-squared:  0.01689,	Adjusted R-squared:  0.01051 
# F-statistic: 2.646 on 1 and 154 DF,  p-value: 0.1058

MASS::stepAIC(lm(dif ~ mxee + trunc + BS ,
                 data = alpha.its[alpha.its$diversity_measure=='Simpson',]))$anova
# Initial Model:
#   dif ~ mxee + trunc + BS
# 
# Final Model:
#   dif ~ mxee + BS
# 
# 
# Step Df   Deviance Resid. Df Resid. Dev       AIC
# 1                             151   3.026622 -605.0158
# 2 - trunc  1 0.03143417       152   3.058057 -605.4039

summary(lm(dif ~ mxee + BS ,data = alpha.its[alpha.its$diversity_measure=='Simpson',]))
# Call:
#   lm(formula = dif ~ mxee + BS, data = alpha.its[alpha.its$diversity_measure == 
#                                                    "Simpson", ])
# 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -0.33122 -0.08635 -0.01379  0.08284  0.25390 
# 
# Coefficients:
#              Estimate Std. Error t value Pr(>|t|)   
# (Intercept) -0.071161   0.022713  -3.133  0.00208 **
# mxeemxee25   0.033541   0.022713   1.477  0.14182   
# BSBS16      -0.002096   0.027817  -0.075  0.94004   
# BSBS32       0.047201   0.027817   1.697  0.09178 . 
# ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.1418 on 152 degrees of freedom
# Multiple R-squared:  0.03918,	Adjusted R-squared:  0.02021 
# F-statistic: 2.066 on 3 and 152 DF,  p-value: 0.1071

colnames(alpha_diff)[3]='samp'
final_eval_tab = merge(final_eval_tab,
                           alpha_diff[alpha_diff$diversity_measure=='Simpson',
                                      c('samp','dif')],
                           by = 'samp')
colnames(final_eval_tab)[ncol(final_eval_tab)]='Simpson_diff'

final_eval_tab = merge(final_eval_tab,
                       alpha_diff[alpha_diff$diversity_measure=='Shannon',
                                  c('samp','dif')],
                       by = 'samp')
colnames(final_eval_tab)[ncol(final_eval_tab)]='Shannon_diff'
head(final_eval_tab)
# samp bank rich tp fp tn fn recall precision       f1s tpr
# 1   clus99_B1_k10_w10_COICP12_Filt CP12    1  0  1 19  2    0.0 0.0000000       NaN 0.0
# 2 clus99_B1_k10_w10_COICP12_NoFilt CP12    3  2  1 19  0    1.0 0.6666667 0.8000000 1.0
# 3     clus99_B1_k10_w10_COIM1_Filt   M1    2  2  0 17  3    0.4 1.0000000 0.5714286 0.4
# 4   clus99_B1_k10_w10_COIM1_NoFilt   M1   12  5  7 10  0    1.0 0.4166667 0.5882353 1.0
# 5    clus99_B1_k10_w10_COIM11_Filt  M11    3  2  1 16  3    0.4 0.6666667 0.5000000 0.4
# 6  clus99_B1_k10_w10_COIM11_NoFilt  M11    8  5  3 14  0    1.0 0.6250000 0.7692308 1.0
# fpr       tnr       fnr                   method barcode complex      bray      jacc
# 1 0.05000000 0.9500000 1.0000000   clus99_B1_k10_w10_Filt     COI       2 1.0000000 1.0000000
# 2 0.05000000 0.9500000 0.0000000 clus99_B1_k10_w10_NoFilt     COI       2 0.4074512 0.5789915
# 3 0.00000000 1.0000000 0.7500000   clus99_B1_k10_w10_Filt     COI      11 0.7342484 0.8467627
# 4 0.41176471 0.5882353 0.0000000 clus99_B1_k10_w10_NoFilt     COI      11 0.7665976 0.8678803
# 5 0.05882353 0.9411765 0.8181818   clus99_B1_k10_w10_Filt     COI      11 0.7628590 0.8654793
# 6 0.17647059 0.8235294 0.0000000 clus99_B1_k10_w10_NoFilt     COI      11 0.7575794 0.8620713
# Simpson_diff Shannon_diff
# 1    0.5000000   0.69314718
# 2    0.1628774   0.05869024
# 3    0.3284701   0.74374896
# 4    0.4080115   0.75986217
# 5    0.2678639   0.57101023
# 6    0.4248828   0.80647707

################
####-------- Missing assignment rate between the two barcodes and across pipelines
################

#### Store missing rate
nalist_sp = rownames(tax_table(gp)[which(is.na(tax_table(gp)[,7]))])

df_na = otu_table(gp)[which(rownames(otu_table(gp)) %in% nalist_sp),]
df_na = df_na[,which(colSums(df_na)>0)]
df_na = reshape2::melt(df_na)

#df_na$Name = names$Names[match(df_na$Var1,names$nalist)]

pdf(file = './TaxonomyMissingRate.pdf',width = 14,height = 8)
ggplot(df_na,aes(x = Var2, y = value)) + 
  geom_bar(stat = 'identity') + facet_wrap(~ Var1, scales = 'free') +
  coord_flip() + ylab('') +
  theme(legend.position = 'bottom',
        text = element_text(size = 10),
        axis.text.y = element_text(size = 4))
dev.off()

### No major difference between BS parameters > stick to BS16
tax_mis = aggregate(value ~ Var2, df_na, FUN=sum)
colnames(tax_mis) = c('samp','Taxonomy_missing_rate')


### Add Taxonomy assignment missing rate 
taxmis.coi = tax_mis[grep('COI',tax_mis$samp),]
taxmis.coi
#                               samp Taxonomy_missing_rate
# 157  clus99_B1_k10_w8_COIM2_NoFilt          4.781763e-06
# 158  clus99_B1_k13_w8_COIM2_NoFilt          4.783088e-06
# 159  clus99_B2_k10_w8_COIM2_NoFilt          4.720300e-06
# 160 clus99_B2_k13_w10_COIM2_NoFilt          4.721463e-06
# 161  clus99_B4_k10_w8_COIM2_NoFilt          4.223147e-06
# 162 clus99_B4_k10_w10_COIM2_NoFilt          4.221591e-06
# 163  clus99_B4_k13_w8_COIM2_NoFilt          4.221765e-06
# 164 clus99_B4_k13_w10_COIM2_NoFilt          4.222437e-06

taxmis.its = tax_mis[grep('ITS',tax_mis$samp),]
taxmis.its$mxee = sapply(stringr::str_split(taxmis.its$samp,"_"),function(x) x[1])
taxmis.its$trunc = sapply(stringr::str_split(taxmis.its$samp,"_"),function(x) x[2])
taxmis.its$BS = sapply(stringr::str_split(taxmis.its$samp,"_"),function(x) x[3])

MASS::stepAIC(lm(Taxonomy_missing_rate ~ mxee + trunc + BS, data = taxmis.its))$anova
# Initial Model:
#   Taxonomy_missing_rate ~ mxee + trunc + BS
# 
# Final Model:
#   Taxonomy_missing_rate ~ trunc + BS
# 
# 
# Step Df   Deviance Resid. Df Resid. Dev      AIC
# 1                            147   3.006832 -586.295
# 2 - mxee  1 0.01833397       148   3.025166 -587.371

summary(lm(Taxonomy_missing_rate ~ trunc + BS , data = taxmis.its))
# Call:
# lm(formula = Taxonomy_missing_rate ~ trunc + BS, data = taxmis.its)
# 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -0.28882 -0.12966  0.03344  0.09755  0.27070 
# 
# Coefficients:
#                Estimate Std. Error t value Pr(>|t|)    
# (Intercept)    0.348760   0.022975  15.180  < 2e-16 ***
# trunctrunc217 -0.060899   0.023218  -2.623 0.009631 ** 
# BSBS16         0.005782   0.028039   0.206 0.836893    
# BSBS32        -0.107618   0.028633  -3.759 0.000245 ***
#   ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.143 on 148 degrees of freedom
# Multiple R-squared:  0.1477,	Adjusted R-squared:  0.1305 
# F-statistic: 8.551 on 3 and 148 DF,  p-value: 2.836e-05

summary(lm(Taxonomy_missing_rate ~ BS , 
           data = taxmis.its[taxmis.its$mxee=='mxee25' & taxmis.its$trunc=='trunc200',]))
# Call:
#   lm(formula = Taxonomy_missing_rate ~ BS, data = taxmis.its[taxmis.its$mxee == 
#                                                                "mxee25" & taxmis.its$trunc == "trunc200", ])
# 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -0.23158 -0.04118  0.01456  0.10307  0.16558 
# 
# Coefficients:
#             Estimate Std. Error t value Pr(>|t|)    
# (Intercept)  0.30740    0.03171   9.694 1.42e-11 ***
# BSBS16      -0.05370    0.04485  -1.198   0.2389    
# BSBS32      -0.07770    0.04485  -1.733   0.0917 .  
# ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.1143 on 36 degrees of freedom
# Multiple R-squared:  0.08041,	Adjusted R-squared:  0.02932 
# F-statistic: 1.574 on 2 and 36 DF,  p-value: 0.2212

### Add Taxonomy assignment missing rate 
final_eval_tab$Taxonomy_missing_rate = 0
final_eval_tab$Taxonomy_missing_rate[match(tax_mis$samp,final_eval_tab$samp)] = tax_mis$Taxonomy_missing_rate

summary(mis_dada2$value)
#      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
# 0.0000042 0.0709180 0.2551263 0.2242424 0.3380745 0.5173096 


eval_to_plot = final_eval_tab[final_eval_tab$method=='clus99_B4_k10_w10_NoFilt'|
                                final_eval_tab$method=='mxee11_trunc200_BS32',  ]
eval_to_plot = eval_to_plot[,c('samp','bank','f1s','method','barcode','bray','jacc','complex',
                               'Simpson_diff', 'Shannon_diff','Taxonomy_missing_rate')]
eval_to_plot$complex = factor(eval_to_plot$complex)
colnames(eval_to_plot) = c('Sample','Bank','A - F1-score','Method',
                           'Barcode','B - Divergence (Bray-Curtis)','C - Divergence (Jaccard)',
                           'Mock community size',
                           'D - Difference in \n alpha-diversity (Simpson)', 'E - Difference in \n alpha-diversity (Shannon)',
                           'F - Fraction of \n reads unassigned')
eval_to_plot = reshape2::melt(eval_to_plot,c('Sample','Bank','Method','Barcode','Mock community size'))

p = ggplot(eval_to_plot,aes(x = `Mock community size`, y = value, fill = Barcode)) +
  geom_boxplot(alpha = .8) +
  facet_wrap(~ variable, scales = 'free') +
  theme_classic() + ylab('Coefficient value') +
  theme(strip.background = element_blank(),
        legend.position = 'bottom',
        text = element_text(size = 12), 
        strip.text = element_text(size = 10))

pdf(file = './Figure1.pdf')
ggpubr::set_palette(p,'jco')
dev.off()

eval_to_plot = final_eval_tab[final_eval_tab$method=='clus99_B4_k10_w10_NoFilt'|
                                final_eval_tab$method=='mxee11_trunc200_BS32',  ]
eval_to_plot = eval_to_plot[,c('samp','bank','f1s','method','barcode','bray','jacc','complex',
                               'Simpson_diff', 'Shannon_diff','Taxonomy_missing_rate')]
eval_to_plot$complex = factor(eval_to_plot$complex)
colnames(eval_to_plot) = c('Sample','Bank','F1-score','Method',
                           'Barcode','Divergence (Bray-curtis)','Divergence (Jaccard)',
                           'Mock community size',
                           'Difference in alpha-diversity\n(Simpson)', 'Difference in alpha-diversity\n(Shannon)',
                           'Fraction of \n reads unassigned')
eval_to_plot = reshape2::melt(eval_to_plot,c('Sample','Bank','Method','Barcode','Mock community size'))

### Test for the difference between ITS-2 and COI
summary.aov(lm(value ~ `Mock community size`*Barcode,
   data = eval_to_plot[eval_to_plot$variable=='F1-score',]))
#                               Df  Sum Sq  Mean Sq F value Pr(>F)  
# `Mock community size`          2 0.05963 0.02982   3.210 0.0629 .
# Barcode                        1 0.00245 0.00245   0.264 0.6134  
# `Mock community size`:Barcode  2 0.06643 0.03321   3.576 0.0481 *
# Residuals                     19 0.17646 0.00929  

summary.aov(lm(value ~ `Mock community size`*Barcode,
           data = eval_to_plot[eval_to_plot$variable=='Divergence (Bray-curtis)',]))
#                                   Df Sum Sq Mean Sq F value   Pr(>F)    
# `Mock community size`          2 0.4505 0.22523  16.630 6.69e-05 ***
# Barcode                        1 0.0592 0.05920   4.371  0.05022 .  
# `Mock community size`:Barcode  2 0.1927 0.09637   7.116  0.00494 ** 
# Residuals                     19 0.2573 0.01354

summary(lm(value ~ `Mock community size`*Barcode,
               data = eval_to_plot[eval_to_plot$variable=='Divergence (Bray-curtis)',]))
#                                     Estimate Std. Error t value Pr(>|t|)    
# (Intercept)                         0.26830    0.05819   4.611 0.000191 ***
# `Mock community size`5              0.45563    0.08229   5.537 2.43e-05 ***
# `Mock community size`11             0.42791    0.08229   5.200 5.10e-05 ***
# BarcodeITS                          0.10515    0.07294   1.442 0.165719    
# `Mock community size`5:BarcodeITS  -0.32474    0.12441  -2.610 0.017205 *  
# `Mock community size`11:BarcodeITS -0.38755    0.10996  -3.524 0.002267 ** 
   
summary.aov(lm(value ~ `Mock community size`*Barcode,
           data = eval_to_plot[eval_to_plot$variable=='Divergence (Jaccard)',]))
#                               Df Sum Sq Mean Sq F value   Pr(>F)    
# `Mock community size`          2 0.4052 0.20260  12.101 0.000408 ***
# Barcode                        1 0.0224 0.02236   1.336 0.262119    
# `Mock community size`:Barcode  2 0.1764 0.08819   5.267 0.015136 *  
# Residuals                     19 0.3181 0.01674

summary(lm(value ~ `Mock community size`*Barcode,
               data = eval_to_plot[eval_to_plot$variable=='Divergence (Jaccard)',]))
#                                    Estimate Std. Error t value Pr(>|t|)    
# (Intercept)                          0.3991     0.0647   6.168  6.3e-06 ***
# `Mock community size`5               0.4390     0.0915   4.798 0.000125 ***
# `Mock community size`11              0.4200     0.0915   4.590 0.000200 ***
# BarcodeITS                           0.1349     0.0811   1.664 0.112573    
# `Mock community size`5:BarcodeITS   -0.3110     0.1383  -2.248 0.036639 *  
# `Mock community size`11:BarcodeITS  -0.3706     0.1223  -3.031 0.006871 ** 
  
summary.aov(lm(value ~ `Mock community size`*Barcode,
           data = eval_to_plot[eval_to_plot$variable=='Difference in alpha-diversity\n(Simpson)',]))
#                               Df Sum Sq Mean Sq F value   Pr(>F)    
# `Mock community size`          2 0.4415  0.2208   9.118 0.001675 ** 
# Barcode                        1 0.5542  0.5542  22.890 0.000129 ***
# `Mock community size`:Barcode  2 0.1682  0.0841   3.474 0.051785 .  
# Residuals                     19 0.4600  0.0242           

summary.aov(lm(value ~ `Mock community size`*Barcode,
           data = eval_to_plot[eval_to_plot$variable=='Difference in alpha-diversity\n(Shannon)',]))
#                               Df Sum Sq Mean Sq F value   Pr(>F)    
# `Mock community size`          2  4.433  2.2166  26.908 2.86e-06 ***
# Barcode                        1  2.875  2.8753  34.906 1.09e-05 ***
# `Mock community size`:Barcode  2  1.008  0.5041   6.119  0.00888 ** 
# Residuals                     19  1.565  0.0824

##### Cyathostomum sp. // 2-species mock communities
summary.aov(lm(value ~ Barcode,
               data = eval_to_plot[eval_to_plot$variable=='F1-score' &
                                     eval_to_plot$`Mock community size`==2,]))
#             Df  Sum Sq Mean Sq F value Pr(>F)
# Barcode      1 0.02545 0.02545   1.909    0.2
# Residuals    9 0.12000 0.01333  
summary(lm(value ~ Barcode,
           data = eval_to_plot[eval_to_plot$variable=='Divergence (Bray-curtis)' &
                                 eval_to_plot$`Mock community size`==2,]))
# Residuals:
#   Min        1Q    Median        3Q       Max 
# -0.227470 -0.092463 -0.007838  0.131296  0.170758 
# 
# Coefficients:
#             Estimate Std. Error t value Pr(>|t|)   
# (Intercept)  0.26830    0.07065   3.798  0.00423 **
# BarcodeITS   0.10515    0.08857   1.187  0.26554   
# ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.1413 on 9 degrees of freedom
# Multiple R-squared:  0.1354,	Adjusted R-squared:  0.03933 
# F-statistic: 1.409 on 1 and 9 DF,  p-value: 0.2655

summary(lm(value ~ Barcode,
           data = eval_to_plot[eval_to_plot$variable=='Divergence (Jaccard)' &
                                 eval_to_plot$`Mock community size`==2,]))
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -0.32058 -0.09464  0.00148  0.15391  0.18681 
# 
# Coefficients:
#             Estimate Std. Error t value Pr(>|t|)   
# (Intercept)   0.3991     0.0860   4.640  0.00122 **
# BarcodeITS    0.1349     0.1078   1.252  0.24227   
# ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.172 on 9 degrees of freedom
# Multiple R-squared:  0.1483,	Adjusted R-squared:  0.05361 
# F-statistic: 1.567 on 1 and 9 DF,  p-value: 0.2423

summary.aov(lm(value ~ Barcode,
               data = eval_to_plot[eval_to_plot$variable=='Difference in alpha-diversity\n(Simpson)' &
                                     eval_to_plot$`Mock community size`==2,]))
# Df  Sum Sq Mean Sq F value Pr(>F)
# Barcode      1 0.03321 0.03321   0.956  0.354
# Residuals    9 0.31251 0.03472
summary.aov(lm(value ~ Barcode,
               data = eval_to_plot[eval_to_plot$variable=='Difference in alpha-diversity\n(Shannon)' &
                                     eval_to_plot$`Mock community size`==2,]))
# Df Sum Sq Mean Sq F value Pr(>F)
# Barcode      1 0.1451 0.14508   1.557  0.244
# Residuals    9 0.8386 0.09318

aggregate(Taxonomy_missing_rate ~ barcode + complex, data = final_eval_tab,FUN=mean)
# barcode complex Taxonomy_missing_rate
# 1     COI       2          0.000000e+00
# 2     ITS       2          2.724389e-01
# 3     COI       5          0.000000e+00
# 4     ITS       5          1.709757e-01
# 5     COI      11          2.527856e-07
# 6     ITS      11          3.469107e-01

##### Supplementary Table 1
write.csv(final_eval_tab,file = './supplementary_Table2.csv',row.names = F,quote=F)

#rm(list=ls())

############################## From now on - mxee 11 trunc 200 - BS 32 for ITS-2 ##############################
############################## From now on - B4 w10 k10 MQ0 for COI ##############################

## Helper function for correcting COI sequence names
rename_mini_otu = function(df){
  
  #unique(df$V1)
  
  df$V1[df$V1=="catinatum_Cyathostomum"]='Cyathostomum_catinatum'
  df$V1[df$V1=="nassatus_Cylicocyclus"]='Cylicocyclus_nassatus'
  df$V1[df$V1=="goldi_Cylicostephanus"]='Cylicostephanus_goldi'
  
  df$V1[df$V1=="insigne_Cylicocyclus"]='Cylicocyclus_insigne'
  df$V1[df$V1=="auriculatus_Cylicocyclus"]='Cylicocyclus_auriculatus'
  df$V1[df$V1=="radiatus_Cylicocyclus"]='Cylicocyclus_radiatus'
  df$V1[df$V1=="minutus_Cylicostephanus"]='Cylicostephanus_minutus'
  df$V1[df$V1=="bicoronatus_Cylicodontophorus"]='Cylicodontophorus_bicoronatus'
  df$V1[df$V1=='nipponicus_Triodontophorus']='Triodontophorus_nipponicus'
  df$V1[df$V1=='serratus_Triodontophorus']='Triodontophorus_serratus'
  df$V1[df$V1=='brevicauda_Triodontophorus']='Triodontophorus_brevicauda'
  df$V1[df$V1=='vulgaris_Strongylus']='Strongylus_vulgaris'
  df$V1[df$V1=='imparidentatum_Poteriostomum']='Poteriostomum_imparidentatum'
  
  df$V1[grep('vulgaris_NA',df$V1)]='Strongylus_vulgaris'
  df$V1[grep('goldi_NA',df$V1)]='Cylicostephanus_goldi'
  df$V1[grep('minutus_NA',df$V1)]='Cylicostephanus_minutus'
  df$V1[grep('brevicauda_NA',df$V1)]='Triodontophorus_brevicauda'
  df$V1[grep('insigne_NA',df$V1)]='Cylicocyclus_insigne'
  df$V1[grep('auriculatus_NA',df$V1)]='Cylicocyclus_auriculatus'
  df$V1[grep('catinatum_NA',df$V1)]='Cyathostomum_catinatum'
  df$V1[grep('nassatus_NA',df$V1)]='Cylicocyclus_nassatus'
  df$V1[grep('ashworthi_NA',df$V1)]='Cylicocyclus_ashworthi'
  df$V1[grep('pateratum_NA',df$V1)]='Cyathostomum_pateratum'
  df$V1[grep('labiatus_NA',df$V1)]='Coronocyclus_labiatus'
  df$V1[grep('radiatus_NA',df$V1)]='Cylicocyclus_radiatus'
  df$V1[grep('nipponicus_NA',df$V1)]='Triodontophorus_nipponicus'
  
  df$V1[grep('C.nassatus_5.8S',df$V1)]='Cylicocyclus_nassatus'
  df$V1[grep('C.ashworthi_5.8S',df$V1)]='Cylicocyclus_ashworthi'
  
  df$V1[grep('C.catinatum_ribosomal',df$V1)]='Cyathostomum_catinatum'
  df$V1[grep('pateratum',df$V1)]='Cyathostomum_pateratum'
  df$V1[grep('insignis',df$V1)]='Cylicocyclus_insigne'
  df$V1[grep('labratum',df$V1)]='Coronocyclus_labratus'
  df$V1[grep('ashworthi',df$V1)]='Cylicocyclus_ashworthi'
  df$V1[grep('Cyathostomum_coronatum',df$V1)]='Coronocyclus_coronatus'
  df$V1[grep('Cyathostominae_sp.',df$V1)]='NA_NA'
  df$V1[grep('Cyathostominae',df$V1)]='NA_NA'
  
  return(df)
}

####-------- Create COI phyloseq object
id = 99
B = 4
k = 10
w = 10
miniNofilt <- sort(list.files(paste0('./mock_MINIMAP/mock_MINIMAPm_clus',id,'_B',B,'_k',k,'_w',w ), 
                              pattern = "^COI.*L001_nofilt_genomecov_d.txt.gz", full.names = TRUE))
ministats <- sort(list.files(paste0('./mock_MINIMAP/mock_MINIMAPm_clus',id,'_B',B,'_k',k,'_w',w ), 
                              pattern = "^COI.*idxstats.txt.gz", full.names = TRUE))
otumini = NULL
rcomini = NULL

#### Process read count data

for(f in ministats){
  samp = str_extract(basename(f), "^[^_]+")
  
  ## Read in genome cov stats
  rco = read.table(file = f)
  rco = rco[,c(1,3)]
  
  ## Get rid of sequence positions with no read mapped
  rco = rco[rco$V3!=0,]
  
  if(sum(rco$V3)>0){
    rco$V1 = sapply(stringr::str_split(rco$V1,"_"),function(x) paste(x[1],x[2],x[3],sep="_"))
    rco$V1 = sapply(stringr::str_split(rco$V1,"_"),function(x) paste(x[2],x[3],sep="_"))
    
    ## Compute total coverage corrected by seq length (percoentage coverage)
    a = aggregate(V3 ~ V1, FUN = sum, data = rco)
    a = data.frame(a)
    a$samp = samp
    rcomini = rbind(rcomini,a)
  }
}

#### Process coverage data
for(f in miniNofilt){
  samp = str_extract(basename(f), "^[^_]+")
  
  ## Read in genome cov stats
  mn = read.table(file = f)
  
  ## Extract seq length (nb of occurrences in the file)
  seqlen = data.frame(table(mn$V1))
  colnames(seqlen)[1]='V1'
  colnames(seqlen)[2]='Seqlen'
  
  ## Get rid of sequence positions with no read mapped
  mn = mn[mn$V3!=0,]
  
  if(sum(mn$V3)>0){
    mn$V1 = sapply(stringr::str_split(mn$V1,"_"),function(x) paste(x[1],x[2],x[3],sep="_"))
    mn$V1 = sapply(stringr::str_split(mn$V1,"_"),function(x) paste(x[2],x[3],sep="_"))
    seqlen$V1 = sapply(stringr::str_split(seqlen$V1,"_"),function(x) paste(x[1],x[2],x[3],sep="_"))
    seqlen$V1 = sapply(stringr::str_split(seqlen$V1,"_"),function(x) paste(x[2],x[3],sep="_"))
    
    ## Compute total coverage corrected by seq length (percentage coverage)
    a = aggregate(V3 ~ V1, FUN = sum, data = mn)
    a = data.frame(a)
    a$samp = samp
    a$Filt = 'NoFilt'
    a = merge(a,seqlen,by = 'V1')
    a$FracCov = a$V3/a$Seqlen
    otumini = rbind(otumini,a)
  }
}

###------ Need to correct wrong species names for COI
unique(otumini$V1)
# [1] "catinatum_Cyathostomum"        "Cyathostomum_catinatum"        "Cyathostomum_pateratum"        "Cylicocyclus_nassatus"        
# [5] "nassatus_Cylicocyclus"         "pateratum_Cyathostomum"        "Coronocyclus_labiatus"         "Cylicocyclus_ashworthi"       
# [9] "Cylicocyclus_insigne"          "Cylicostephanus_calicatus"     "Cylicostephanus_longibursatus" "Cylicostephanus_minutus"      
# [13] "goldi_Cylicostephanus"         "insigne_Cylicocyclus"          "Cyathostominae_NA"             "ashworthi_Cylicocyclus"       
# [17] "Coronocyclus_coronatus"        "Cylicocyclus_radiatus"         "radiatus_Cylicocyclus"

otumini = rename_mini_otu(otumini)
unique(otumini$V1)
# [1] "Cylicocyclus_ashworthi"        "Cyathostomum_catinatum"        "Coronocyclus_coronatus"        "Coronocyclus_labiatus"        
# [5] "Cyathostomum_pateratum"        "Cylicocyclus_insigne"          "Cylicocyclus_nassatus"         "Cylicostephanus_calicatus"    
# [9] "Cylicostephanus_longibursatus" "Cylicostephanus_minutus"       "Cylicostephanus_goldi"         "Cylicocyclus_radiatus"        
# [13] "Poteriostomum_imparidentatum"  "Triodontophorus_nipponicus"    "NA_NA"                         "Strongylus_vulgaris"          
# [17] "Triodontophorus_serratus"      "Triodontophorus_brevicauda"

rcomini = rename_mini_otu(rcomini)
unique(rcomini$V1)
# [1] "Cyathostomum_catinatum"        "Cyathostomum_pateratum"        "Cylicocyclus_nassatus"         "Cylicocyclus_ashworthi"       
# [5] "Coronocyclus_labiatus"         "Cylicocyclus_insigne"          "Cylicostephanus_calicatus"     "Cylicostephanus_longibursatus"
# [9] "Cylicostephanus_minutus"       "Cylicostephanus_goldi"         "NA_NA"                         "Coronocyclus_coronatus"       
# [13] "Cylicocyclus_radiatus"

###-------- Sum read counts by species
rco_sum = aggregate(V3 ~ V1 + samp, data = rcomini, FUN = sum)
###-------- Convert sample name fo subsequent processing
rco_sum$samp = gsub('-','',rco_sum$samp)
rco_sum$samp = paste0('clus',id,'_B',B,'_k',k,'_w',w,'_',rco_sum$samp)
colnames(rco_sum) = c('species','samp','ReadCount')
head(rco_sum)
# species                      samp ReadCount
# 1 Cyathostomum_catinatum clus99_B4_k10_w10_COICP12     54062
# 2 Cyathostomum_pateratum clus99_B4_k10_w10_COICP12      5984
# 3  Cylicocyclus_nassatus clus99_B4_k10_w10_COICP12       416
# 4  Coronocyclus_labiatus   clus99_B4_k10_w10_COIM1     13294
# 5 Cyathostomum_catinatum   clus99_B4_k10_w10_COIM1       626
# 6 Cyathostomum_pateratum   clus99_B4_k10_w10_COIM1       434

###-------- Convert minimap output to phyloseq object
require(car)
dt = otumini %>% reshape2::acast(samp ~ V1, value.var = 'FracCov',fun.aggregate = sum)
dt = data.frame(dt)

ranks <- c("kingdom","phylum", "class", "order", "family", "genus", "species") # ranks of interest
tax.out <- matrix(NA_character_, nrow = ncol(dt), ncol = length(ranks))
rownames(tax.out) = colnames(dt)

filltax = c('Animalia','Nematoda','Chromadorea','Rhabditida','Strongylidae')
for(i in seq(ncol(tax.out))){
  tax.out[,i] = filltax[i]
}

tax.out[,6] = sapply(stringr::str_split(colnames(dt),"_"),
                     function(x) x[1])
tax.out[,7] = rownames(tax.out)
tax.out[tax.out[,7]=='NA_NA',7] = NA
unique(tax.out[,7])
# [1] "Coronocyclus_coronatus"        "Coronocyclus_labiatus"         "Cyathostomum_catinatum"        "Cyathostomum_pateratum"       
# [5] "Cylicocyclus_ashworthi"        "Cylicocyclus_insigne"          "Cylicocyclus_nassatus"         "Cylicocyclus_radiatus"        
# [9] "Cylicostephanus_calicatus"     "Cylicostephanus_goldi"         "Cylicostephanus_longibursatus" "Cylicostephanus_minutus"      
# [13] NA 

colnames(tax.out) = ranks

#### Add metadata
metadata = data.frame(sample.id = paste0('clus',id,'_B',B,'_k',k,'_w',w,'_',rownames(dt)))
metadata$sample.id = gsub('-','',metadata$sample.id)
rownames(dt) = metadata$sample.id
rownames(metadata) = metadata$sample.id
metadata$bank = gsub(paste0('clus',id,'_B',B,'_k',k,'_w',w,'_'),'',metadata$sample.id)
metadata$bank = gsub('COI','',metadata$bank)
metadata$method = paste0('clus',id,'_B',B,'_k',k,'_w',w)
metadata$nsp = 2
metadata$nsp[metadata$bank %in% c('Meq','MeqC12','MS10','MS10C12')] = 11
metadata$nsp[metadata$bank %in% c("M1","M11","M2","M21")] = 5
metadata$bank[metadata$bank =='CP12']='M41'
metadata$Replicate = 1
metadata$Replicate[metadata$bank %in% c('M11','M21','M41','M51','MeqC12','MS10C12')] = 2
metadata$bank = substr(metadata$bank,1,2)

## Remove contaminants - overall count below 10 or FracCov < 100 put to 0
dt_filt = dt
dt_filt[dt_filt < 100] <- 0 ## remove spurious signal; at least 100% bases covered
dt_filt = dt_filt[,which(colSums(dt_filt) > 10)] ## remove contaminants

psCOI = phyloseq(
  otu_table(dt_filt, taxa_are_rows = FALSE),
  tax_table(tax.out),
  sample_data(metadata))

ps.coi = tax_glom(psCOI,taxrank='species',NArm=F)
ps.coi
# phyloseq-class experiment-level object
# otu_table()   OTU Table:         [ 10 taxa and 12 samples ]
# sample_data() Sample Data:       [ 12 samples by 3 sample variables ]
# tax_table()   Taxonomy Table:    [ 10 taxa by 7 taxonomic ranks ]


### Update read counts to retain the only species found after contaminant removal 
otu_filt = data.frame(otu_table(ps.coi))
otu_filt$samp = rownames(otu_filt)
otu_filt = reshape2::melt(otu_filt,'samp')
colnames(otu_filt)[2] = 'species'

read_count_coi = merge(otu_filt,rco_sum,by = c('samp','species'))
read_count_coi = read_count_coi[read_count_coi$value > 0,]

## Remove contaminants
rm(miniNofilt,otumini,dt)

### Examine C. coronatus / C. minutus
read_count_coi[read_count_coi$species=='Coronocyclus_coronatus',]
#                            samp                species value ReadCount bank Replicate
# 48     clus99_B4_k10_w10_COIMeq Coronocyclus_coronatus   125         8   Me         1
# 58  clus99_B4_k10_w10_COIMeqC12 Coronocyclus_coronatus  9527       604   Me         1
# 68    clus99_B4_k10_w10_COIMS10 Coronocyclus_coronatus   348        24   MS         1
# 78 clus99_B4_k10_w10_COIMS10C12 Coronocyclus_coronatus  3937       253   MS         1

read_count_coi[read_count_coi$species=='Cylicostephanus_minutus',]
#                           samp                 species value ReadCount bank Replicate
# 67 clus99_B4_k10_w10_COIMeqC12 Cylicostephanus_minutus   215        11   Me         1

ps.coi.t = transform_sample_counts(ps.coi,function(x) x/sum(x))

####-------- Create ITS phyloseq object
truncL = 200
mxee = 11
bc = 'ITS'
BS = 32

### Read in seqtab
seqtab_nochim = read.table(file = paste0('./mock_DADA2/mock_dada2_R_',bc,'_mxee',mxee,'_trunc',truncL,'_BS',BS,'/output.tsv'),
                           header=T)

dim(seqtab_nochim)
#[1] 130 14

dna <- DNAStringSet(getSequences(seqtab_nochim$OTUID))
seqtab_nochim$OTUID = paste0('ASV_',1:nrow(seqtab_nochim))
rownames(seqtab_nochim) = seqtab_nochim$OTUID
names(dna) = seqtab_nochim$OTUID
seqtab_nochim$OTUID = NULL

colnames(seqtab_nochim) = sapply(stringr::str_split(colnames(seqtab_nochim),'_'),
                                 function(x) x[1])

colnames(seqtab_nochim) = paste0('mxee',mxee,'_trunc',truncL,'_BS',BS,'_',
                                 gsub('[.]','',colnames(seqtab_nochim)))


metadata = data.frame(sample.id = colnames(seqtab_nochim))
rownames(metadata) = metadata$sample.id
metadata$bank = gsub(paste0('mxee',mxee,'_trunc',truncL,'_BS',BS,'_'),'',metadata$sample.id)
metadata$bank = gsub('ITS','',metadata$bank)

metadata$method = paste0('mxee',mxee,'_trunc',truncL,'_BS',BS)
metadata$nsp = 2
metadata$nsp[metadata$bank %in% c('Meq','MS10')] = 11
metadata$nsp[metadata$bank %in% c("M1","M11","M2","M21")] = 5
metadata$mxee = mxee
metadata$truncation = truncL
metadata$BS = BS
metadata$bank[metadata$bank =='CP']='M42'
metadata$Replicate = 1
metadata$Replicate[metadata$bank %in% c('M11','M21','M31','M41','M51')] = 2
metadata$Replicate[metadata$bank =='M42'] = 3
metadata$bank = substr(metadata$bank,1,2)

taxmeth = 'idtaxa'
train <- readDNAStringSet("~/db/idtaxa_03022022.fasta") 
tax <- read_tsv("~/db/idtaxa_03022022.tax") 

trainingSet <- LearnTaxa(train, names(train), tax)
#dna <- DNAStringSet(getSequences(seqtab_nochim))

ids <- IdTaxa(dna,
              trainingSet,
              strand = "both",
              threshold = 50,
              bootstraps = 100,
              processors = NULL,
              verbose = TRUE,
              type = "extended")

ranks <- c("kingdom","phylum", "class", "order", "family", "genus", "species") # ranks of interest
# Convert the output object of class "Taxa" to a matrix analogous to the output from assignTaxonomy
taxidITS <- t(sapply(ids, function(x) {
  m <- match(ranks, x$rank)
  taxa <- x$taxon[m]
  taxa[startsWith(taxa, "unclassified_")] <- NA
  taxa
}))
colnames(taxidITS) <- ranks; rownames(taxidITS) <- names(dna) #getSequences(seqtab_nochim)


ps = phyloseq(
  otu_table(seqtab_nochim, taxa_are_rows = TRUE),
  tax_table(taxidITS),
  sample_data(metadata))

# Phyloseq obj
psITS = tax_glom(ps,taxrank='species',NArm=F)
psITS
# phyloseq-class experiment-level object
# otu_table()   OTU Table:         [ 16 taxa and 13 samples ]
# sample_data() Sample Data:       [ 13 samples by 3 sample variables ]
# tax_table()   Taxonomy Table:    [ 16 taxa by 7 taxonomic ranks ]

## Remove contaminants
psITS =  filter_taxa(psITS, function(x) sum(x) > 40, TRUE)
psITS
# phyloseq-class experiment-level object
# otu_table()   OTU Table:         [ 13 taxa and 13 samples ]
# sample_data() Sample Data:       [ 13 samples by 8 sample variables ]
# tax_table()   Taxonomy Table:    [ 13 taxa by 7 taxonomic ranks ]

otu_table(psITS)

####################################################################
####-------- 1. Replicability across run 
####################################################################

###- ITS-2
otu = data.frame(t(as.matrix(otu_table(psITS))))
otu$sample.id = rownames(otu)
otu = merge(otu,data.frame(sample_data(psITS)),by='sample.id')

## Keep banks with replicates in both ITS-2 and COI ; ITS-2 has replicates for c('M1','M2','M3,'M4','M5')
otu_rep = otu[otu$bank %in% c('M1','M2') & otu$Replicate %in% c(1,2),]
otu_rep = reshape2::melt(otu_rep,c('sample.id', 'bank','method', 'nsp', 'Replicate'))

df = data.frame(Replicate1 = otu_rep$value[otu_rep$Replicate==1],
                Replicate2 = otu_rep$value[otu_rep$Replicate==2])
df$Species = otu_rep$variable[otu_rep$Replicate==1]
df$nsp = factor(otu_rep$nsp[otu_rep$Replicate==1])
ggplot(df,aes(x = Replicate1, y = Replicate2, col = nsp)) + 
  geom_point() + 
  scale_x_continuous(limits = c(0,3000)) + scale_y_continuous(limits = c(0,3000)) 

Hmisc::rcorr(df$Replicate1,df$Replicate2,'spearman')
#      x    y
# x 1.00 0.98
# y 0.98 1.00
# 
# n= 32

otu_rep.its = otu_rep
rm(otu,otu_rep)

###- COI
otu = data.frame(as.matrix(otu_table(ps.coi)))
otu$sample.id = rownames(otu)
otu = merge(otu,data.frame(sample_data(ps.coi)),by='sample.id')

## Keep banks with replicates in both ITS-2 and COI ; COI has replicates for c('M1','M2','M4', 'MS', 'Me')
otu_rep = otu[otu$bank %in% c('M1','M2') & otu$Replicate %in% c(1,2),]
otu_rep = otu_rep[order(otu_rep$bank,otu_rep$Replicate),]
otu_rep = reshape2::melt(otu_rep,c('sample.id', 'bank','method', 'nsp', 'Replicate'))

df = data.frame(Replicate1= otu_rep$value[otu_rep$Replicate==1],
                Replicate2 = otu_rep$value[otu_rep$Replicate==2])
df$Species = otu_rep$variable[otu_rep$Replicate==1]
df$nsp = factor(otu_rep$nsp[otu_rep$Replicate==1])
ggplot(df,aes(x = Replicate1, y = Replicate2, col = nsp)) + 
  geom_point() + 
  scale_x_continuous(limits = c(0,3000)) + scale_y_continuous(limits = c(0,3000)) 

Hmisc::rcorr(df$Replicate1,df$Replicate2,'spearman')
# x    y
# x 1.00 0.98
# y 0.98 1.00
# 
# n= 20 

otu_rep.coi = otu_rep
rm(otu,otu_rep)

####################################################################
####-------- 2. Does DNA amount correlates with recovered reads counts ?
####################################################################
##-- ITS-2
dna = data.frame(otu.mock)
dna$Species = rownames(dna)
dna = reshape2::melt(dna)
dna$variable = substr(dna$variable,1,2)
dna = unique(dna)

otu_rep.its$variable = factor(tax_table(psITS)[match(otu_rep.its$variable,rownames(tax_table(psITS))),7])
otu_rep.its$dna = dna$value[match(paste0(otu_rep.its$bank,otu_rep.its$variable),paste0(dna$variable,dna$Species))]
otu_rep.its$Replicate = factor(otu_rep.its$Replicate)

## Retain species of interest (found in DNA or counts)
a = aggregate(dna ~ variable,data=otu_rep.its,FUN=sum)
b =  aggregate(value ~ variable,data=otu_rep.its,FUN=sum)

sp_to_elim = as.character(a$variable[a$dna==0 & b$value ==0])

otu_rep.its = na.omit(otu_rep.its)
otu_rep.its = otu_rep.its[!(otu_rep.its$variable %in% sp_to_elim),]
# Remove false positives
sp_fp = c('Cylicostephanus_longibursatus','Cylicocyclus_ashworthi',
          'Coronocyclus_labratus','Cylicocyclus_leptostomus','Cylicocyclus_calicatus')
otu_rep.its = otu_rep.its[!(otu_rep.its$variable %in% sp_fp),]

m1 = lm(log(dna+.01) ~ log(value+1) + variable + Replicate, 
       data = otu_rep.its)
summary(m1)$r.squared
#[1] 0.8669372

m2 = lm(log(dna+.01) ~ log(value+1) + variable,
        data = otu_rep.its)
summary(m2)$r.squared
#[1] 0.8578433

m3 = lm(log(dna+.01) ~ log(value+1) + Replicate, 
        data = otu_rep.its)
summary(m3)$r.squared
#[1]  0.5715852
summary.aov(m3)
#                Df Sum Sq Mean Sq F value   Pr(>F)    
# log(value + 1)  1  5.109   5.109   22.48 0.000189 ***
# Replicate       1  0.045   0.045    0.20 0.660344    
# Residuals      17  3.863   0.227

AIC(m1,m2,m3)$AIC - min(AIC(m1,m2,m3)$AIC)
#[1]  0.678  0.000 16.063

## Remove C. ashworthi detection in M3
otu_rep.its$Replicate = paste0("Replicate",otu_rep.its$Replicate)
otu_rep.its$variable = gsub('_',' ',otu_rep.its$variable)

p1 = ggplot(otu_rep.its[!(otu_rep.its$variable %in% sp_fp),],
            aes(x = log(dna+.01), y = log(value+1)))+
  theme_classic() +
  geom_abline(slope = 1,intercept = 0,col = 'darkgrey',lty = 2) +
  scale_y_continuous(limits = c(0,7), breaks = seq(0,7)) + 
  facet_wrap(~ Replicate, ncol = 2,scales='free') + 
  ylab('Log(read count+1)') +
  xlab('Log([DNA]+0.01)') + 
  geom_smooth(method = 'lm',se = F,lwd = .5,col='black',lty=2) + 
  geom_point(size = 3, alpha = .6, aes(x = log(dna+.01), y = log(value+1),color = otu_rep.its$variable)) + 
  theme(legend.position = 'bottom', 
        legend.title = element_blank(),
        text = element_text(size = 14),
        strip.background = element_blank()) + 
  guides(col = guide_legend (nrow = 2))

Hmisc::rcorr(log(.01+otu_rep.its$dna),log(otu_rep.its$value+1))
# x    y
# x 1.00 0.75
# y 0.79 1.00
# 
# n= 20 

##-- For COI we rely on idxstats counts for the sequences retained after filtering

dna = data.frame(otu.mock)
dna$species = rownames(dna)
dna = reshape2::melt(dna)
dna$variable = substr(dna$variable,1,2)
dna = unique(dna)

read_count_coi$bank = sapply(stringr::str_split(read_count_coi$samp,'_'),function(x) gsub('COI','',x[5]))
colnames(dna)[2]='bank'
read_count_coi$Replicate = 1
read_count_coi$Replicate[read_count_coi$bank %in% c('M11','M21')] = 2
read_count_coi$bank = substr(read_count_coi$bank,1,2)

otu_rep.coi = merge(read_count_coi[,-c(3)],dna,by = c('species','bank'))
otu_rep.coi$Replicate = factor(otu_rep.coi$Replicate)
otu_rep.coi = otu_rep.coi[otu_rep.coi$bank %in% c('M1','M2') & otu_rep.coi$Replicate %in% c(1,2),]
colnames(otu_rep.coi)[6]='dna'

plot(density(log(otu_rep.coi$dna)))

m1 = lm(log(dna+.01) ~ log(ReadCount) + species + Replicate, 
        data = otu_rep.coi)
summary(m1)$r.squared
#[1] 0.7392426

m2 = lm(log(dna+.01) ~ log(ReadCount) + species,
        data = otu_rep.coi)
summary(m2)$r.squared
#[1] 0.7392253

m3 = lm(log(dna+.01) ~ log(ReadCount) + Replicate, 
        data = otu_rep.coi)
summary(m3)$r.squared
#[1] 0.04313643

summary.aov(m3)
#                Df Sum Sq Mean Sq F value Pr(>F)
# log(ReadCount)  1  0.389  0.3886   0.766  0.394
# Replicate       1  0.000  0.0004   0.001  0.979
# Residuals      17  8.629  0.5076

AIC(m1,m2,m3)$AIC - min(AIC(m1,m2,m3)$AIC)
#[1] 1.998675  0.000000 20.000078

otu_rep.coi$Replicate = paste0("Replicate",otu_rep.coi$Replicate)
otu_rep.coi$species = gsub('_',' ',otu_rep.coi$species)
  
p2 = ggplot(otu_rep.coi,aes(x = log(dna+.01), y = log(ReadCount+1), col = species))+
  theme_classic() + 
  geom_abline(slope = 1,intercept = 0,col = 'darkgrey',lty = 2) +
  facet_wrap(~ Replicate, ncol = 2,scales='free') + 
  scale_y_continuous(limits = c(1,12),breaks = seq(1,12)) +
  ylab('Log(read count+1)') +
  xlab('Log([DNA]+0.01)') + 
  geom_smooth(method = 'lm',se = F,lwd = .5,col='black',lty=2) + 
  geom_point(size = 3, alpha = .6,aes(x = log(dna+.01), y = log(ReadCount+1),color = otu_rep.coi$species)) + 
  theme(legend.position = 'bottom', 
        legend.title = element_blank(),
        text = element_text(size = 14),
        strip.background = element_blank()) + 
  guides(col = guide_legend (nrow = 2))

pdf(file = './Figure2.pdf')
multiplot(p1,p2)
dev.off()

Hmisc::rcorr(log(.01+otu_rep.coi$dna),log(otu_rep.coi$ReadCount))
# x    y
# x  1.0 -0.21
# y -0.21  1.0
# 
# n= 20 
# 
# 
# P
# x      y     
# x        0.3798

####################################################################
####-------- 3. qPCR efficacies - data production by Elise Courtot
####################################################################
eff = read.csv(file = './BarcodeEfficiency.csv',header=T,sep=';')
eff = eff[eff$Efficiency>0 & eff$Efficiency<1,] ### Remove aberrant values for Cylicostephanus species
aggregate(Efficiency~ Barcode , data= eff, FUN =mean)
# Barcode Efficiency
# 1   COX-1      0.680
# 2   ITS-2      0.926

aggregate(Efficiency~ Barcode , data= eff, FUN =sd)
# Barcode Efficiency
# 1   COX-1     0.2361
# 2   ITS-2     0.0307
t.test(Efficiency ~ Barcode, data = eff)
# data:  Efficiency by Barcode
# t = -3, df = 10, p-value = 0.006
# alternative hypothesis: true difference in means is not equal to 0
# 95 percent confidence interval:
#   -0.4057 -0.0868
# sample estimates:
#   mean in group COX-1 mean in group ITS-2 
# 0.680               0.926 

####################################################################
####-------- 4. How do life-stages compare to describe a community ?
####################################################################
pal = qualpalr::qualpal(n=27, colorspace=list(h=c(0,360), s=c(0.3,1), l=c(0.2,0.8)))

############################------------------------------- COI data

miniNofilt <- sort(list.files('./life_stage/mock_MINIMAPm_clus99_B4_k10_w10/',
                              pattern = "^COI.*L001_nofilt_genomecov_d.txt.gz", full.names = TRUE))
ministats <- sort(list.files('./life_stage/mock_MINIMAPm_clus99_B4_k10_w10/',
                             pattern = "^COI.*idxstats.txt.gz", full.names = TRUE))
otumini = NULL
rcomini = NULL

#### Process read count data

for(f in ministats){
  samp = str_extract(basename(f), "^[^_]+")
  
  ## Read in genome cov stats
  rco = read.table(file = f)
  rco = rco[,c(1,3)]
  
  ## Get rid of sequence positions with no read mapped
  rco = rco[rco$V3!=0,]
  
  if(sum(rco$V3)>0){
    rco$V1 = sapply(stringr::str_split(rco$V1,"_"),function(x) paste(x[1],x[2],x[3],sep="_"))
    rco$V1 = sapply(stringr::str_split(rco$V1,"_"),function(x) paste(x[2],x[3],sep="_"))
    
    ## Compute total coverage corrected by seq length (percoentage coverage)
    a = aggregate(V3 ~ V1, FUN = sum, data = rco)
    a = data.frame(a)
    a$samp = samp
    rcomini = rbind(rcomini,a)
  }
}

#### Process coverage data
for(f in miniNofilt){
  samp = str_extract(basename(f), "^[^_]+")
  
  ## Read in genome cov stats
  mn = read.table(file = f)
  
  ## Extract seq length (nb of occurrences in the file)
  seqlen = data.frame(table(mn$V1))
  colnames(seqlen)[1]='V1'
  colnames(seqlen)[2]='Seqlen'
  
  ## Get rid of sequence positions with no read mapped
  mn = mn[mn$V3!=0,]
  
  if(sum(mn$V3)>0){
    mn$V1 = sapply(stringr::str_split(mn$V1,"_"),function(x) paste(x[1],x[2],x[3],sep="_"))
    mn$V1 = sapply(stringr::str_split(mn$V1,"_"),function(x) paste(x[2],x[3],sep="_"))
    seqlen$V1 = sapply(stringr::str_split(seqlen$V1,"_"),function(x) paste(x[1],x[2],x[3],sep="_"))
    seqlen$V1 = sapply(stringr::str_split(seqlen$V1,"_"),function(x) paste(x[2],x[3],sep="_"))
    
    ## Compute total coverage corrected by seq length (percentage coverage)
    a = aggregate(V3 ~ V1, FUN = sum, data = mn)
    a = data.frame(a)
    a$samp = samp
    a$Filt = 'NoFilt'
    a = merge(a,seqlen,by = 'V1')
    a$FracCov = a$V3/a$Seqlen
    otumini = rbind(otumini,a)
  }
}

###------ Need to correct wrong species names for COI
unique(otumini$V1)
# [1] "catinatum_Cyathostomum"        "Cyathostomum_catinatum"        "Cyathostomum_pateratum"        "Cylicocyclus_nassatus"        
# [5] "nassatus_Cylicocyclus"         "pateratum_Cyathostomum"        "Coronocyclus_labiatus"         "Cylicocyclus_ashworthi"       
# [9] "Cylicocyclus_insigne"          "Cylicostephanus_calicatus"     "Cylicostephanus_longibursatus" "Cylicostephanus_minutus"      
# [13] "goldi_Cylicostephanus"         "insigne_Cylicocyclus"          "Cyathostominae_NA"             "ashworthi_Cylicocyclus"       
# [17] "Coronocyclus_coronatus"        "Cylicocyclus_radiatus"         "radiatus_Cylicocyclus"

otumini = rename_mini_otu(otumini)
unique(otumini$V1)
# [1] "Cyathostomum_catinatum"        "Cyathostomum_pateratum"        "Cylicocyclus_nassatus"         "Coronocyclus_labiatus"        
# [5] "Cylicocyclus_ashworthi"        "Cylicocyclus_insigne"          "Cylicostephanus_calicatus"     "Cylicostephanus_longibursatus"
# [9] "Cylicostephanus_minutus"       "Cylicostephanus_goldi"         "NA_NA"                         "Coronocyclus_coronatus"       
# [13] "Cylicocyclus_radiatus" 

rcomini = rename_mini_otu(rcomini)
unique(rcomini$V1)
# [1] "Cylicocyclus_ashworthi"        "Cyathostomum_catinatum"        "Coronocyclus_coronatus"        "Coronocyclus_labiatus"        
# [5] "Cyathostomum_pateratum"        "Cylicocyclus_insigne"          "Cylicocyclus_nassatus"         "Cylicostephanus_calicatus"    
# [9] "Cylicostephanus_longibursatus" "Cylicostephanus_minutus"       "Cylicostephanus_goldi"         "Cylicocyclus_radiatus"        
# [13] "Poteriostomum_imparidentatum"  "Triodontophorus_nipponicus"    "NA_NA"                         "Strongylus_vulgaris"          
# [17] "Triodontophorus_serratus"      "Triodontophorus_brevicauda" 

###-------- Sum read counts by species
rco_sum = aggregate(V3 ~ V1 + samp, data = rcomini, FUN = sum)
###-------- Convert sample name fo subsequent processing
colnames(rco_sum) = c('species','samp','ReadCount')
head(rco_sum)
#                  species        samp ReadCount
# 1 Coronocyclus_coronatus COIEggs-646      2023
# 2  Coronocyclus_labiatus COIEggs-646         3
# 3 Cyathostomum_catinatum COIEggs-646      5119
# 4 Cyathostomum_pateratum COIEggs-646      2684
# 5 Cylicocyclus_ashworthi COIEggs-646         4
# 6   Cylicocyclus_insigne COIEggs-646         1

###-------- Convert minimap output to phyloseq object
require(car)
dt = otumini %>% reshape2::acast(samp ~ V1, value.var = 'FracCov',fun.aggregate = sum)
dt = data.frame(dt)

ranks <- c("kingdom","phylum", "class", "order", "family", "genus", "species") # ranks of interest
tax.out <- matrix(NA_character_, nrow = ncol(dt), ncol = length(ranks))
rownames(tax.out) = colnames(dt)

filltax = c('Animalia','Nematoda','Chromadorea','Rhabditida','Strongylidae')
for(i in seq(ncol(tax.out))){
  tax.out[,i] = filltax[i]
}

tax.out[,6] = sapply(stringr::str_split(colnames(dt),"_"),
                     function(x) x[1])
tax.out[,7] = rownames(tax.out)
tax.out[tax.out[,7]=='NA_NA',7] = NA
unique(tax.out[,7])
# [1] "Coronocyclus_coronatus"        "Coronocyclus_labiatus"         "Cyathostomum_catinatum"        "Cyathostomum_pateratum"       
# [5] "Cylicocyclus_ashworthi"        "Cylicocyclus_insigne"          "Cylicocyclus_nassatus"         "Cylicocyclus_radiatus"        
# [9] "Cylicostephanus_calicatus"     "Cylicostephanus_goldi"         "Cylicostephanus_longibursatus" "Cylicostephanus_minutus"      
# [13] NA                              "Poteriostomum_imparidentatum"  "Strongylus_vulgaris"           "Triodontophorus_brevicauda"   
# [17] "Triodontophorus_nipponicus"    "Triodontophorus_serratus"

colnames(tax.out) = ranks

#### Add metadata
metadata = data.frame(sample.id = rownames(dt),
                      Horse = sapply(stringr::str_split(rownames(dt),'-'),
                                     function(x) gsub('.COI','',x[2])),
                      Type = gsub('COI','',gsub('J42','L3',sapply(stringr::str_split(rownames(dt),'-'),
                                                                       function(x) x[1])))
                      )
rownames(metadata) = rownames(dt)

## Remove contaminants - overall count below 10 or FracCov < 100 put to 0
dt_filt = dt
dt_filt[dt_filt < 100] <- 0 ## remove spurious signal; at least 100% bases covered
dt_filt = dt_filt[,which(colSums(dt_filt) > 10)] ## remove contaminants

psCOI = phyloseq(
  otu_table(dt_filt, taxa_are_rows = FALSE),
  tax_table(tax.out),
  sample_data(metadata))

ps.coi = tax_glom(psCOI,taxrank='species',NArm=T)
ps.coi
# phyloseq-class experiment-level object
# otu_table()   OTU Table:         [ 12 taxa and 25 samples ]
# sample_data() Sample Data:       [ 25 samples by 3 sample variables ]
# tax_table()   Taxonomy Table:    [ 12 taxa by 7 taxonomic ranks ]

ps.coi.t = transform_sample_counts(ps.coi,function(x) x/sum(x))

#### Remove samples that do not have data for the three sample type
samp_to_keep_coi = names(table(metadata$Horse)[which(table(metadata$Horse)==3)])
ps.coi.f = subset_samples(ps.coi,Horse %in% samp_to_keep_coi)
ps.coi.t.f = subset_samples(ps.coi.t,Horse %in% samp_to_keep_coi)

############################------------------------------- ITS data

### Read in seqtab with full scale experiment data
seqtab_nochim = read.table(file = './life_stage/dada2_R_mxee11_trunc200_BS32/output.tsv', header=T)
dim(seqtab_nochim)
#[1] 345 100
colnames(seqtab_nochim) = gsub('[.]','-',colnames(seqtab_nochim))
colnames(seqtab_nochim) = sapply(stringr::str_split(colnames(seqtab_nochim),'_'),
                                 function(x) gsub('ITS','',x[1]))

metadata0 = data.frame(sample.id = colnames(seqtab_nochim),
                       Horse = sapply(stringr::str_split(colnames(seqtab_nochim),'-'),
                                      function(x) gsub('ITS','',x[2])),
                       ID = sapply(stringr::str_split(colnames(seqtab_nochim),'-'),
                                   function(x) gsub('ITS','',x[1])),
                       Type = gsub('J42','L3',sapply(stringr::str_split(colnames(seqtab_nochim),'-'),
                                                     function(x) x[1]))
)
samp_to_keep_its = metadata0$Horse[metadata0$Type=='Eggs' & !(metadata0$ID %in% c('J0','J28','J35'))]
samp_to_keep_its
#[1] "646" "710" "717" "720" "726" "729" "733" "734" "748" "755"

col_to_keep = c(1,which(sapply(stringr::str_split(colnames(seqtab_nochim),"-"),
                           function(x) x[2]) %in% samp_to_keep_its &
                      !(sapply(stringr::str_split(colnames(seqtab_nochim),"-"),
                               function(x) x[1]) %in% c('J0','J28','J35'))))
seqtab_nochim = seqtab_nochim[,col_to_keep]
dim(seqtab_nochim)
#[1] 345  27
rm(metadata0)

### Metadata
metadata = data.frame(sample.id = colnames(seqtab_nochim),
                       Horse = sapply(stringr::str_split(colnames(seqtab_nochim),'-'),
                                      function(x) gsub('ITS','',x[2])),
                       Type = gsub('J42','L3',sapply(stringr::str_split(colnames(seqtab_nochim),'-'),
                                                     function(x) x[1]))
)
rownames(metadata)=metadata$sample.id

### Build phyloseq object
dna <- DNAStringSet(getSequences(seqtab_nochim$OTUID))
seqtab_nochim$OTUID = paste0('ASV_',1:nrow(seqtab_nochim))
rownames(seqtab_nochim) = seqtab_nochim$OTUID
names(dna) = seqtab_nochim$OTUID
seqtab_nochim$OTUID = NULL

### Taxonomy assignemnt
taxmeth = 'idtaxa'
train <- readDNAStringSet("~/db/idtaxa_03022022.fasta") 
tax <- read_tsv("~/db/idtaxa_03022022.tax") 

trainingSet <- LearnTaxa(train, names(train), tax)
#dna <- DNAStringSet(getSequences(seqtab_nochim))

ids <- IdTaxa(dna,
              trainingSet,
              strand = "both",
              threshold = 50,
              bootstraps = 100,
              processors = NULL,
              verbose = TRUE,
              type = "extended")

ranks <- c("kingdom","phylum", "class", "order", "family", "genus", "species") # ranks of interest
# Convert the output object of class "Taxa" to a matrix analogous to the output from assignTaxonomy
taxidITS <- t(sapply(ids, function(x) {
  m <- match(ranks, x$rank)
  taxa <- x$taxon[m]
  taxa[startsWith(taxa, "unclassified_")] <- NA
  taxa
}))
colnames(taxidITS) <- ranks; rownames(taxidITS) <- names(dna) #getSequences(seqtab_nochim)

taxidITS[which(is.na(taxidITS[,7]) & taxidITS[,6]=='Cyathostomum'),7] = 'Cyathostomum_sp'
taxidITS[which(is.na(taxidITS[,7]) & taxidITS[,6]=='Cylicocyclus'),7] = 'Cylicocyclus_sp'
taxidITS[which(is.na(taxidITS[,7]) & taxidITS[,6]=='Cylicostephanus'),7] = 'Cylicostephanus_sp'
taxidITS[which(is.na(taxidITS[,7]) & taxidITS[,6]=='Coronocyclus'),7] = 'Coronocyclus_sp'

ps = phyloseq(
  otu_table(seqtab_nochim, taxa_are_rows = TRUE),
  tax_table(taxidITS),
  sample_data(metadata))

# Phyloseq obj
psITS = tax_glom(ps,taxrank='species',NArm=T)
psITS
# phyloseq-class experiment-level object
# otu_table()   OTU Table:         [ 21 taxa and 26 samples ]
# sample_data() Sample Data:       [ 26 samples by 3 sample variables ]
# tax_table()   Taxonomy Table:    [ 21 taxa by 7 taxonomic ranks ]

## Remove contaminants
psITS =  filter_taxa(psITS, function(x) sum(x) > 40, TRUE)
psITS
# phyloseq-class experiment-level object
# otu_table()   OTU Table:         [ 17 taxa and 26 samples ]
# sample_data() Sample Data:       [ 26 samples by 3 sample variables ]
# tax_table()   Taxonomy Table:    [ 17 taxa by 7 taxonomic ranks ]

#### Remove samples that do not have data for the three sample type & not found for the COI
samp_to_keep_its = names(table(metadata$Horse)[which(table(metadata$Horse)==3)])
samp_to_keep_its
#[1] "646" "710" "729" "733" "734" "748" "755"

ps.its.f = subset_samples(psITS,Horse %in% samp_to_keep_coi)
ps.its.t.f = transform_sample_counts(ps.its.f,function(x) x/sum(x))

ps.coi.f
# phyloseq-class experiment-level object
# otu_table()   OTU Table:         [ 12 taxa and 18 samples ]
# sample_data() Sample Data:       [ 18 samples by 3 sample variables ]
# tax_table()   Taxonomy Table:    [ 12 taxa by 7 taxonomic ranks ]

sp.coi = data.frame(unique(tax_table(ps.coi.f)[,7]))
sp.coi$species
# [1] "Coronocyclus_coronatus"        "Coronocyclus_labiatus"         "Cyathostomum_catinatum"        "Cyathostomum_pateratum"       
# [5] "Cylicocyclus_ashworthi"        "Cylicocyclus_insigne"          "Cylicocyclus_nassatus"         "Cylicocyclus_radiatus"        
# [9] "Cylicostephanus_calicatus"     "Cylicostephanus_goldi"         "Cylicostephanus_longibursatus" "Cylicostephanus_minutus"

ps.its.f
# phyloseq-class experiment-level object
# otu_table()   OTU Table:         [ 17 taxa and 18 samples ]
# sample_data() Sample Data:       [ 18 samples by 3 sample variables ]
# tax_table()   Taxonomy Table:    [ 17 taxa by 7 taxonomic ranks ]

sp.its = data.frame(unique(tax_table(ps.its.f)[,7]))
sp.its$species
# [1] "Cylicocyclus_nassatus"         "Cylicostephanus_minutus"       "Cyathostomum_pateratum"        "Cyathostomum_sp"              
# [5] "Coronocyclus_coronatus"        "Cylicocyclus_leptostomus"      "Cyathostomum_catinatum"        "Cylicostephanus_calicatus"    
# [9] "Coronocyclus_labiatus"         "Cylicocyclus_insigne"          "Cylicostephanus_longibursatus" "Cylicostephanus_goldi"        
# [13] "Cylicocyclus_ashworthi"        "Cylicostephanus_sp"            "Cylicocyclus_sp"               "Coronocyclus_sp"              
# [17] "Craterostomum_acuticaudatum"

### Species found with COI and not with ITS
sp.coi$species[is.na(match(sp.coi$species,sp.its$species))]
#[1] "Cylicocyclus_radiatus"

### Species not found with ITS
sp.its$species[is.na(match(sp.its$species,sp.coi$species))]
# [1] "Cyathostomum_sp"             "Cylicocyclus_leptostomus"    "Cylicostephanus_sp"          "Cylicocyclus_sp"            
# [5] "Coronocyclus_sp"             "Craterostomum_acuticaudatum"


############################------------------------------- ALPHA DIVERSITY

###--- COI
alpha_div_coi <- estimate_richness(ps.coi.f, split = TRUE, measure = "Shannon")
alpha_div_coi$sample.id <- rownames(alpha_div_coi) %>%  as.factor()

alphaplot_coi <- sample_data(ps.coi.f) %>%
  unclass() %>%
  data.frame() %>%
  left_join(alpha_div_coi, by = "sample.id") %>%
  reshape2::melt(measure.vars = "Shannon",
                 variable.name = "diversity_measure",
                 value.name = "alpha_diversity")

palpha.coi = ggplot(alphaplot_coi) +
  geom_point(aes(x = Type, y = alpha_diversity, group = Horse, col = Horse), 
             size = 5, alpha = .4)+
  scale_y_continuous(limits = c(0, 2), breaks = seq(0, 2, .2)) +
  geom_line(aes(x = Type, y = alpha_diversity,group = Horse,
                col = Horse), alpha = .4) + 
  labs(x = "Type", y = "Shannon Diversity", color = "Pipeline") +
  theme(legend.position = 'bottom', text = element_text(size = 16)) 

###--- ITS
alpha_div_its <- estimate_richness(ps.its.f, split = TRUE, measure = "Shannon")
alpha_div_its$sample.id <- rownames(alpha_div_its) %>%  as.factor()

alphaplot_its <- sample_data(ps.its.f) %>%
  unclass() %>%
  data.frame() %>%
  left_join(alpha_div_its, by = "sample.id") %>%
  reshape2::melt(measure.vars = "Shannon",
                 variable.name = "diversity_measure",
                 value.name = "alpha_diversity")

palpha.its = ggplot(alphaplot_its) +
  geom_point(aes(x = Type, y = alpha_diversity, group = Horse, col = Horse), 
             size = 5, alpha = .4)+
  scale_y_continuous(limits = c(0, 2), breaks = seq(0, 2, .2)) +
  geom_line(aes(x = Type, y = alpha_diversity,group = Horse,
                col = Horse), alpha = .4) + 
  labs(x = "Type", y = "Shannon Diversity", color = "Pipeline") +
  theme(legend.position = 'bottom', text = element_text(size = 16)) 

alphatot = rbind(alpha_div_coi,alpha_div_its)
alphatot$Type = metadata$Type[match(gsub('COI','',alphatot$sample.id),metadata$sample.id)]
alphatot$Barcode = 'ITS-2'
alphatot$Barcode[grep('COI',rownames(alphatot))] = 'COI'

mod = lm(Shannon ~ Type + Barcode, data = alphatot)
summary.aov(mod)
#             Df Sum Sq Mean Sq F value  Pr(>F)   
# Type         2  0.021  0.0104   0.044 0.95682   
# Barcode      1  1.786  1.7863   7.580 0.00964 **
# Residuals   32  7.541  0.2356 

summary(mod)
# Call:
#   lm(formula = Shannon ~ Type + Barcode, data = alphatot)
# 
# Residuals:
#   Min       1Q   Median       3Q      Max 
# -1.01279 -0.34210 -0.00626  0.32498  0.75110 
# 
# Coefficients:
#               Estimate Std. Error t value Pr(>|t|)    
# (Intercept)   0.620529   0.161810   3.835 0.000556 ***
# TypeL3       -0.053246   0.198176  -0.269 0.789901    
# TypePool     -0.004771   0.198176  -0.024 0.980944    
# BarcodeITS-2  0.445505   0.161810   2.753 0.009643 ** 
#   ---
#   Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1
# 
# Residual standard error: 0.4854 on 32 degrees of freedom
# Multiple R-squared:  0.1933,	Adjusted R-squared:  0.1177 
# F-statistic: 2.556 on 3 and 32 DF,  p-value: 0.07258

a = aggregate(Shannon ~ Type + Barcode,data = alphatot,FUN='mean')
a$std = aggregate(Shannon ~ Type + Barcode,data = alphatot,FUN='sd')[,3]
a
#   Type Barcode   Shannon       std
# 1 Eggs     COI 0.5797792 0.3560519
# 2   L3     COI 0.6472481 0.3179222
# 3 Pool     COI 0.5765424 0.4629224
# 4 Eggs   ITS-2 1.1067831 0.4730973
# 5   L3   ITS-2 0.9328227 0.6551552
# 6 Pool   ITS-2 1.1004785 0.6244095

####--------- NMDS
pslog.its <- transform_sample_counts(ps.its.f, function(x) log(1 + x))
pslog.coi <- transform_sample_counts(ps.coi.f, function(x) log(1 + x))

## MDS Bray - ITS-2
out.bra.log.its <- ordinate(pslog.its, method = "NMDS", distance = "bray")
evals.its <- out.bra.log.its$values$Eigenvalues

## plot
p.NMDS.its = plot_ordination(pslog.its, out.bra.log.its, 
                    color = "Horse", shape  = "Type") +
  geom_point(size = 6, alpha = .4) +
  ggtitle('C') + theme(legend.position = 'bottom') +
  theme(legend.position = 'right', text = element_text(size = 12)) 
p.NMDS.its

## MDS Bray - COI
out.bra.log.coi <- ordinate(pslog.coi, method = "NMDS", distance = "bray")
evals.coi <- out.bra.log.coi$values$Eigenvalues

## plot
p.NMDS.coi = plot_ordination(pslog.coi, out.bra.log.coi, 
                             color = "Horse", shape  = "Type") +
  geom_point(size = 6, alpha = .4) +
  ggtitle('B') + theme(legend.position = 'bottom') +
  theme(legend.position = 'right', text = element_text(size = 12)) 
p.NMDS.coi

#### Figure 3
### Plot relative abundances - ITS-2
totsp = data.frame(sp = unique(c(tax_table(ps.its.t.f)[,7],tax_table(ps.coi.t.f)[,7])))
totsp$colsp = pal$hex[match(totsp$sp,levels(factor(totsp$sp)))]

toplot.its = reshape2::melt(otu_table(ps.its.t.f))
toplot.its = data.frame(toplot.its)
toplot.its$species = factor(tax_table(ps.its.t.f)[match(toplot.its$Var1,rownames(tax_table(ps.its.t.f))),7])
toplot.its$colsp = totsp$colsp[match(toplot.its$species,totsp$sp)]
toplot.its$Horse = sapply(stringr::str_split(toplot.its$Var2,'-'),function(x) x[2])
toplot.its$Type = gsub('J42','L3',sapply(stringr::str_split(toplot.its$Var2,'-'),function(x) x[1]))
toplot.its$Barcode = 'ITS'

toplot.coi = reshape2::melt(otu_table(ps.coi.t.f))
toplot.coi = data.frame(toplot.coi)
colnames(toplot.coi)[1] = 'Var1'
colnames(toplot.coi)[2] = 'species'
toplot.coi$species = factor(toplot.coi$species)
toplot.coi$colsp = totsp$colsp[match(toplot.coi$species,totsp$sp)]
toplot.coi$Horse = sapply(stringr::str_split(toplot.coi$Var1,'-'),function(x) x[2])
toplot.coi$Type = gsub('COI','',gsub('J42','L3',sapply(stringr::str_split(toplot.coi$Var1,'-'),function(x) x[1])))
toplot.coi$Barcode = 'COI'

toplot.its = toplot.its[,c('Var1','value','species','Horse','Type','Barcode')]
toplot.coi = toplot.coi[,c('Var1','value','species','Horse','Type','Barcode')]

toplot = rbind(toplot.its,toplot.coi)
toplot$species = factor(toplot$species)
toplot$Horse=paste0('W',toplot$Horse)

pbar = ggplot(toplot, aes(x = Type, y = value, fill = gsub('_',' ',species))) +
    geom_bar(stat = 'identity') +
  scale_fill_manual(values = pal$hex) + 
  facet_wrap(~ paste0(Horse,' - ',Barcode), scales = 'free') +
  ylab('Relative abundance') + xlab('Sample type') +
  theme_classic() + ggtitle('A') +
  theme(legend.position = 'right',text = element_text(size = 12),
        axis.text.x = element_text(size = 10),strip.background = element_blank(),
        legend.title = element_blank(), legend.text = element_text(size = 8))+
  guides(fill = guide_legend(ncol = 1))


library(gridExtra)
library(grid)
library(ggplot2)
library(lattice)

pdf(file = './Figure3.pdf',height = 10, width = 9)
grid.arrange(pbar,p.NMDS.coi,p.NMDS.its, 
             widths = c(1, 1),
             heights = c(0.6,0.4),
             layout_matrix = rbind(c(1, 1),
                                   c(2, 3)))
dev.off()

###--- Test beta-diversity
adonis(vegdist(t(as.matrix(otu_table(ps.its.f))), method="bray") ~ sample_data(ps.its.f)$Type)
# Call:
#   adonis(formula = vegdist(t(as.matrix(otu_table(ps.its.f))), method = "bray") ~      sample_data(ps.its.f)$Type) 
# 
# Permutation: free
# Number of permutations: 999
# 
# Terms added sequentially (first to last)
# 
#                            Df SumsOfSqs MeanSqs F.Model      R2 Pr(>F)
# sample_data(ps.its.f)$Type  2    0.4959 0.24795  0.8317 0.09982  0.625
# Residuals                  15    4.4719 0.29812         0.90018       
# Total                      17    4.9678                 1.00000 

adonis(vegdist(as.matrix(otu_table(ps.coi.f)), method="bray") ~ sample_data(ps.coi.f)$Type)
# Call:
#   adonis(formula = vegdist(as.matrix(otu_table(ps.coi.f)), method = "bray") ~      sample_data(ps.coi.f)$Type) 
# 
# Permutation: free
# Number of permutations: 999
# 
# Terms added sequentially (first to last)
# 
#                            Df SumsOfSqs MeanSqs F.Model      R2 Pr(>F)
# sample_data(ps.coi.f)$Type  2   0.51741 0.25871  1.5129 0.16786  0.122
# Residuals                  15   2.56505 0.17100         0.83214       
# Total                      17   3.08247                 1.00000 

adonis(vegdist(t(as.matrix(otu_table(ps.its.f))), method="jaccard") ~ sample_data(ps.its.f)$Type)
# Call:
#   adonis(formula = vegdist(t(as.matrix(otu_table(ps.its.f))), method = "bray") ~      sample_data(ps.its.f)$Type) 
# 
# Permutation: free
# Number of permutations: 999
# 
# Terms added sequentially (first to last)
# 
#                           Df SumsOfSqs MeanSqs F.Model      R2 Pr(>F)
# sample_data(ps.its.f)$Type  2    0.4959 0.24795  0.8317 0.09982  0.625
# Residuals                  15    4.4719 0.29812         0.90018       
# Total                      17    4.9678                 1.00000 

adonis(vegdist(as.matrix(otu_table(ps.coi.f)), method="jaccard") ~ sample_data(ps.coi.f)$Type)
# Call:
#   adonis(formula = vegdist(as.matrix(otu_table(ps.coi.f)), method = "bray") ~      sample_data(ps.coi.f)$Type) 
# 
# Permutation: free
# Number of permutations: 999
# 
# Terms added sequentially (first to last)
# 
#                            Df SumsOfSqs MeanSqs F.Model      R2 Pr(>F)
# sample_data(ps.coi.f)$Type  2   0.51741 0.25871  1.5129 0.16786  0.122
# Residuals                  15   2.56505 0.17100         0.83214       
# Total                      17   3.08247                 1.00000 

